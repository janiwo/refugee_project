plot(model_greece, type="summary", label="frex")
labelTopics(model = model_greece,
n = 10)
toLDAvis(model_greece, docs = out_greece$documents)
?toLDAvis
?toLDAvis
?toLDAvis
?labelTopics
toLDAvis(model_greece, docs = out_greece$documents)
model_greece <- model_greece_6
# Plot the convergence
plot(model_greece$convergence$bound,
type = "l",
ylab = "Approximate Convergence",
main = "Convergence")
?labelTopics
labelTopics(model = model_greece,
n = 10)
# Plot frequency of topics
plot(model_greece, type="summary", label="frex")
# Plot topic correlations
mod.out.corr <-topicCorr(model_greece)
plot(mod.out.corr)
?toLDAvis
toLDAvis(model_greece, docs = out_greece$documents)
model_greece <- model_greece_7
# Plot the convergence
plot(model_greece$convergence$bound,
type = "l",
ylab = "Approximate Convergence",
main = "Convergence")
labelTopics(model = model_greece,
n = 10)
# Plot frequency of topics
plot(model_greece, type="summary", label="frex")
# Plot topic correlations
mod.out.corr <-topicCorr(model_greece)
plot(mod.out.corr)
?toLDAvis
toLDAvis(model_greece, docs = out_greece$documents)
out_tigray$vocab
stop_uninformative <- strsplit("able absolutely access according account accountable across action actually affected agency agree agreement alive allegation allow allowed allowing almost alone along already also always ambassador amid among another answer anti anymore anyone anything area arent around arrived article asylum attempt attention away back based basic become believe best better black blame blocked born breaking bring brother call called calling came cant case caught cause centre change claim claiming clear clearly close come coming comment commited commiting completely concern concerned condemn condition confirmed  continue continues could country course cover created credible crisis currently daily day deal dear decade decision demand department despite didnt difference different dire doesnt done dont east eastern easy either effort else endf enough especially ethnic even ever every everyone everything evidence evil exactly expect extremely face facility facing fact failed fake false federal feel find first found four forget free fuck fucking full genuine getting given giving great ground group happy imagine including issue instead isnt give going good half hand happen happened happening hard head heading held high horn hour however huge idea image immediate immediately independent information inside internal internally interview investigate investigation issue join journalist keep kind know known lack land landing largest last latest leader least left let letting level lie like likely little live living load local long longer look looking lost made mail major majority make making many massive matter maybe mean medium member middle might migration mind month morning mostly move much must name near nearly need needed neighboring never news next nobody north northern nothing obviously office one ongoing operation others paid part party pas past people perhaps person place plan please point post press prevails prime probably problem process programme provide public push putting question quite rather reach read real realise reality really reason received recent record remains remember report reported reporting resident response responsible rest result right said satellite say saying second seek seeker seeking seem seems seen send sending sent series service several shame share shit show side simple simply since single site situation small someone something soon sorry sort south source speak special spread stand star start started statement street still stop stopped stopping story stupid sure surely system take taken taking talk talking tell term testimony thank thanks thats there theyre thing think though thought three time today told took torn towards town tried true truth trying turn tweet understand unless urgent urgently used using video vice view virus visit voice wait waiting want wanted watch water week welcome well west western withdraw within without whats whilst white whole wing wish wonder wont word world worse wrong would year yesterday young youre"," ")[[1]]
stop_ne <- strsplit("abiy addis aegean afewerki afeworki afghan afghanistan africa african america amnesty ahmed american amhara andrew ankara antony arab asean asia assad aung bachelet balukhali bangladesh bangladeshi biden blinken boris borisjohnson borrell brexit brit britain british brussels bulgaria burma burmese calais canada channel china commission commissioner corona coronavirus council covid cox dover dublin edirne england english erdoan erdogan eritrea eritrean ethiopia ethiopian euro europe european evros farage filippo fontelles france french freya_cole garneau geneva german germany grandi greece greek guterres haavisto hamdayet harris hindu hitsats houthi houthis idlib idp india indian iran iraq isaias isayas isi israel italy jammu jazeera jerry johnson josep junta justin kachin kadra karen kayin kamala kent kenya kurd labour linda lindat_g lebanon lesbos lesvos libya london maikadra manipur marc merkel michelle mizoram moria muslim mutraw myanmar nation nations nationshumanrights nato nazi nigel november oromia oromo pakistan patel president priti putin reuters rohingya rohingyas russia russian samri secretary shimelba shire somalia spain state sudan sudanese syria syrian tegaru tigrai tigrayan tigrayans thai thailand tory tplf trudeau trump turk turkey turkish unhcr unicef union united unsc yemen youtube"," ")[[1]]
stop_model_opt <- strsplit("allow blame center create desparate eastern enter immigration international fake fascist home island journalist leave life live love open opened opened photo political poor propaganda racist safe save stay tear western"," ")[[1]]
stop_cust <- c(stop_uninformative,stop_ne,stop_model_opt)
processed_tigray = textProcessor(df_tigray$text_stm, metadata = df_tigray,
lowercase = FALSE,
removestopwords = FALSE,
removenumbers = FALSE,
removepunctuation = FALSE,
ucp = FALSE,
stem = FALSE,
customstopwords = stop_cust)
# Prepare Docs
?plotRemoved
rows <- nrow(df_tigray)
plotRemoved(processed_tigray$documents,
lower.thresh = seq(as.integer(0.001*rows),
as.integer(0.05*rows)))
?prepDocuments
out_tigray <- prepDocuments(processed_tigray$documents,
processed_tigray$vocab,
processed_tigray$meta,
lower.thresh = 0.005*rows,
upper.thresh = 0.5*rows)
processed_tigray$vocab
out_tigray$vocab
out_rohingya$vocab
rows <- nrow(df_rohingya)
plotRemoved(processed_rohingya$documents,
lower.thresh = seq(as.integer(0.001*rows),
as.integer(0.05*rows)))
rows
processed_rohingya = textProcessor(df_rohingya$text_stm, metadata = df_rohingya,
lowercase = FALSE,
removestopwords = FALSE,
removenumbers = FALSE,
removepunctuation = FALSE,
ucp = FALSE,
stem = FALSE,
customstopwords = stop_cust)
# Prepare Docs
?plotRemoved
rows <- nrow(df_rohingya)
plotRemoved(processed_rohingya$documents,
lower.thresh = seq(as.integer(0.001*rows),
as.integer(0.05*rows)))
?prepDocuments
out_rohingya <- prepDocuments(processed_rohingya$documents,
processed_rohingya$vocab,
processed_rohingya$meta,
lower.thresh = 0.005*rows,
upper.thresh = 0.5*rows)
out_rohingya$vocab
model_tigray_6 <- stm(documents = out_tigray$documents,
vocab = out_tigray$vocab,
K = 6,
prevalence =~ entity + s(day),
data = out_tigray$meta,
init.type = "Spectral",
seed = 42)
model_tigray_7 <- stm(documents = out_tigray$documents,
vocab = out_tigray$vocab,
K = 7,
prevalence =~ entity + s(day),
data = out_tigray$meta,
init.type = "Spectral",
seed = 42)
model_tigray_8 <- stm(documents = out_tigray$documents,
vocab = out_tigray$vocab,
K = 8,
prevalence =~ entity + s(day),
data = out_tigray$meta,
init.type = "Spectral",
seed = 42)
model_tigray <- model_tigray_6
# Plot the convergence
plot(model_tigray$convergence$bound,
type = "l",
ylab = "Approximate Convergence",
main = "Convergence")
labelTopics(model = model_tigray,
n = 10)
labelTopics(model = model_tigray,
n = 10)
# Plot frequency of topics
plot(model_tigray, type="summary")
# Plot topic correlations
mod.out.corr <-topicCorr(model_tigray)
plot(mod.out.corr)
?toLDAvis
toLDAvis(model_tigray, docs = out_tigray$documents)
out_greece <- prepDocuments(processed_greece$documents,
processed_greece$vocab,
processed_greece$meta,
lower.thresh = 0.01*rows,
upper.thresh = 0.5*rows)
out_greece
out_greece$vocab
stop_uninformative <- strsplit("able absolutely access according account accountable across action actually affected agency agree agreement alive allegation allow allowed allowing almost alone along already also always ambassador amid among another answer anti anymore anyone anything area arent around arrived article asylum attempt attention away back based basic become believe best better black blame blocked born breaking bring brother call called calling came cant case caught cause centre change claim claiming clear clearly close come coming comment commited commiting completely concern concerned condemn condition confirmed  continue continues could country course cover created credible crisis currently daily day deal dear decade decision demand department despite didnt difference different dire doesnt done dont east eastern easy either effort else endf enough especially ethnic even ever every everyone everything evidence evil exactly expect extremely face facility facing fact failed fake false federal feel find first found four forget free fuck fucking full genuine getting given giving great ground group happy imagine including issue instead isnt give going good half hand happen happened happening hard head heading held high horn hour however huge idea image immediate immediately independent information inside internal internally interview investigate investigation issue join journalist keep kind know known lack land landing largest last latest leader least left let letting level lie like likely little live living load local long longer look looking lost made mail major majority make making many massive matter maybe mean medium member middle might migration mind month morning mostly move much must name near nearly need needed neighboring never news next nobody north northern nothing obviously office one ongoing operation others paid part party pas past people perhaps person place plan please point post press prevails prime probably problem process programme provide public push putting question quite rather reach read real realise reality really reason received recent record remains remember report reported reporting resident response responsible rest result right said satellite say saying second seek seeker seeking seem seems seen send sending sent series service several shame share shit show side simple simply since single site situation small someone something soon sorry sort south source speak special spread stand star start started statement street still stop stopped stopping story stupid sure surely system take taken taking talk talking tell term testimony thank thanks thats there theyre thing think though thought three time today told took torn towards town tried true truth trying turn tweet understand unless urgent urgently used using video vice view virus visit voice wait waiting want wanted watch water week welcome well west western withdraw within without whats whilst white whole wing wish wonder wont word world worse wrong would year yesterday young youre"," ")[[1]]
stop_ne <- strsplit("abiy addis aegean afewerki afeworki afghan afghanistan africa african america amnesty ahmed american amhara andrew ankara antony arab asean asia assad aung bachelet balukhali bangladesh bangladeshi biden blinken boris borisjohnson borrell brexit brit britain british brussels bulgaria burma burmese calais canada channel china commission commissioner corona coronavirus council covid cox dover dublin edirne england english erdoan erdogan eritrea eritrean ethiopia ethiopian euro europe european evros farage filippo fontelles france french freya_cole garneau geneva german germany grandi greece greek guterres haavisto hamdayet harris hindu hitsats houthi houthis idlib idp india indian iran iraq isaias isayas isi israel italy jammu jazeera jerry johnson josep junta justin kachin kadra karen kayin kamala kent kenya kurd labour linda lindat_g lebanon lesbos lesvos libya london maikadra manipur marc merkel michelle mizoram moria muslim mutraw myanmar nation nations nationshumanrights nato nazi nigel november oromia oromo pakistan patel president priti putin reuters rohingya rohingyas russia russian samri secretary shimelba shire somalia spain state sudan sudanese syria syrian tegaru tigrai tigrayan tigrayans thai thailand tory tplf trudeau trump turk turkey turkish unhcr unicef union united unsc yemen youtube"," ")[[1]]
stop_model_opt <- strsplit("allow blame center create desparate eastern enter immigration international fake fascist home island journalist leave life live love open opened opened photo political poor propaganda racist safe save stay tear western"," ")[[1]]
stop_cust <- c(stop_uninformative,stop_ne,stop_model_opt)
processed_greece = textProcessor(df_greece$text_stm, metadata = df_greece,
lowercase = FALSE,
removestopwords = FALSE,
removenumbers = FALSE,
removepunctuation = FALSE,
ucp = FALSE,
stem = FALSE,
customstopwords = stop_cust)
# Prepare Docs
?plotRemoved
rows <- nrow(df_greece)
plotRemoved(processed_greece$documents,
lower.thresh = seq(as.integer(0.001*rows),
as.integer(0.05*rows)))
rows <- nrow(df_greece)
plotRemoved(processed_greece$documents,
lower.thresh = seq(as.integer(0.001*rows),
as.integer(0.05*rows)))
rows
processed_greece = textProcessor(df_greece$text_stm, metadata = df_greece,
lowercase = FALSE,
removestopwords = FALSE,
removenumbers = FALSE,
removepunctuation = FALSE,
ucp = FALSE,
stem = FALSE,
customstopwords = stop_cust)
stop_uninformative <- strsplit("able absolutely access according account accountable across action actually affected agency agree agreement alive allegation allow allowed allowing almost alone along already also always ambassador amid among another answer anti anymore anyone anything area arent around arrived article asylum attempt attention away back based basic become believe best better black blame blocked born breaking bring brother call called calling came cant case caught cause centre change claim claiming clear clearly close come coming comment commited commiting completely concern concerned condemn condition confirmed  continue continues could country course cover created credible crisis currently daily day deal dear decade decision demand department despite didnt difference different dire doesnt done dont east eastern easy either effort else endf enough especially ethnic even ever every everyone everything evidence evil exactly expect extremely face facility facing fact failed fake false federal feel find first found four forget free fuck fucking full genuine getting given giving great ground group happy imagine including issue instead isnt give going good half hand happen happened happening hard head heading held high horn hour however huge idea image immediate immediately independent information inside internal internally interview investigate investigation issue join journalist keep kind know known lack land landing largest last latest leader least left let letting level lie like likely little live living load local long longer look looking lost made mail major majority make making many massive matter maybe mean medium member middle might migration mind month morning mostly move much must name near nearly need needed neighboring never news next nobody north northern nothing obviously office one ongoing operation others paid part party pas past people perhaps person place plan please point post press prevails prime probably problem process programme provide public push putting question quite rather reach read real realise reality really reason received recent record remains remember report reported reporting resident response responsible rest result right said satellite say saying second seek seeker seeking seem seems seen send sending sent series service several shame share shit show side simple simply since single site situation small someone something soon sorry sort south source speak special spread stand star start started statement street still stop stopped stopping story stupid sure surely system take taken taking talk talking tell term testimony thank thanks thats there theyre thing think though thought three time today told took torn towards town tried true truth trying turn tweet understand unless urgent urgently used using video vice view virus visit voice wait waiting want wanted watch water week welcome well west western withdraw within without whats whilst white whole wing wish wonder wont word world worse wrong would year yesterday young youre"," ")[[1]]
stop_ne <- strsplit("abiy addis aegean afewerki afeworki afghan afghanistan africa african america amnesty ahmed american amhara andrew ankara antony arab asean asia assad aung bachelet balukhali bangladesh bangladeshi biden blinken boris borisjohnson borrell brexit brit britain british brussels bulgaria burma burmese calais canada channel china commission commissioner corona coronavirus council covid cox dover dublin edirne england english erdoan erdogan eritrea eritrean ethiopia ethiopian euro europe european evros farage filippo fontelles france french freya_cole garneau geneva german germany grandi greece greek guterres haavisto hamdayet harris hindu hitsats houthi houthis idlib idp india indian iran iraq isaias isayas isi israel italy jammu jazeera jerry johnson josep junta justin kachin kadra karen kayin kamala kent kenya kurd labour linda lindat_g lebanon lesbos lesvos libya london maikadra manipur marc merkel michelle mizoram moria muslim mutraw myanmar nation nations nationshumanrights nato nazi nigel november oromia oromo pakistan patel president priti putin reuters rohingya rohingyas russia russian samri secretary shimelba shire somalia spain state sudan sudanese syria syrian tegaru tigrai tigrayan tigrayans thai thailand tory tplf trudeau trump turk turkey turkish unhcr unicef union united unsc yemen youtube"," ")[[1]]
stop_model_opt <- strsplit("allow blame center create desparate eastern enter immigration international fake fascist home island journalist leave life live love open opened opened photo political poor propaganda racist safe save stay tear western"," ")[[1]]
stop_cust <- c(stop_uninformative,stop_ne,stop_model_opt)
# --------------------------------------------------------
# ------------------- Process greece data ----------------
# --------------------------------------------------------
?textProcessor
processed_greece = textProcessor(df_greece$text_stm, metadata = df_greece,
lowercase = FALSE,
removestopwords = FALSE,
removenumbers = FALSE,
removepunctuation = FALSE,
ucp = FALSE,
stem = FALSE,
customstopwords = stop_cust)
# Prepare Docs
?plotRemoved
rows <- nrow(df_greece)
plotRemoved(processed_greece$documents,
lower.thresh = seq(as.integer(0.001*rows),
as.integer(0.05*rows)))
?prepDocuments
out_greece <- prepDocuments(processed_greece$documents,
processed_greece$vocab,
processed_greece$meta,
lower.thresh = 0.01*rows,
upper.thresh = 0.5*rows)
# --------------------------------------------------------
# ------------------- Process channel data ----------------
# --------------------------------------------------------
processed_channel = textProcessor(df_channel$text_stm, metadata = df_channel,
lowercase = FALSE,
removestopwords = FALSE,
removenumbers = FALSE,
removepunctuation = FALSE,
ucp = FALSE,
stem = FALSE,
customstopwords = stop_cust)
stop_uninformative <- strsplit("able absolutely access according account accountable across action actually affected agency agree agreement alive allegation allow allowed allowing almost alone along already also always ambassador amid among another answer anti anymore anyone anything area arent around arrived article asylum attempt attention away back based basic become believe best better black blame blocked born breaking bring brother call called calling came cant case caught cause centre change claim claiming clear clearly close come coming comment commited commiting completely concern concerned condemn condition confirmed  continue continues could country course cover created credible crisis currently daily day deal dear decade decision demand department despite didnt difference different dire doesnt done dont east eastern easy either effort else endf enough especially ethnic even ever every everyone everything evidence evil exactly expect extremely face facility facing fact failed fake false federal feel find first found four forget free fuck fucking full genuine getting given giving great ground group happy imagine including issue instead isnt give going good half hand happen happened happening hard head heading held high horn hour however huge idea image immediate immediately independent information inside internal internally interview investigate investigation issue join journalist keep kind know known lack land landing largest last latest leader least left let letting level lie like likely little live living load local long longer look looking lost made mail major majority make making many massive matter maybe mean medium member middle might migration mind month morning mostly move much must name near nearly need needed neighboring never news next nobody north northern nothing obviously office one ongoing operation others paid part party pas past people perhaps person place plan please point post press prevails prime probably problem process programme provide public push putting question quite rather reach read real realise reality really reason received recent record remains remember report reported reporting resident response responsible rest result right said satellite say saying second seek seeker seeking seem seems seen send sending sent series service several shame share shit show side simple simply since single site situation small someone something soon sorry sort south source speak special spread stand star start started statement street still stop stopped stopping story stupid sure surely system take taken taking talk talking tell term testimony thank thanks thats there theyre thing think though thought three time today told took torn towards town tried true truth trying turn tweet understand unless urgent urgently used using video vice view virus visit voice wait waiting want wanted watch water week welcome well west western withdraw within without whats whilst white whole wing wish wonder wont word world worse wrong would year yesterday young youre"," ")[[1]]
stop_ne <- strsplit("abiy addis aegean afewerki afeworki afghan afghanistan africa african america amnesty ahmed american amhara andrew ankara antony arab asean asia assad aung bachelet balukhali bangladesh bangladeshi biden blinken boris borisjohnson borrell brexit brit britain british brussels bulgaria burma burmese calais canada channel china commission commissioner corona coronavirus council covid cox dover dublin edirne england english erdoan erdogan eritrea eritrean ethiopia ethiopian euro europe european evros farage filippo fontelles france french freya_cole garneau geneva german germany grandi greece greek guterres haavisto hamdayet harris hindu hitsats houthi houthis idlib idp india indian iran iraq isaias isayas isi israel italy jammu jazeera jerry johnson josep junta justin kachin kadra karen kayin kamala kent kenya kurd labour linda lindat_g lebanon lesbos lesvos libya london maikadra manipur marc merkel michelle mizoram moria muslim mutraw myanmar nation nations nationshumanrights nato nazi nigel november oromia oromo pakistan patel president priti putin reuters rohingya rohingyas russia russian samri secretary shimelba shire somalia spain state sudan sudanese syria syrian tegaru tigrai tigrayan tigrayans thai thailand tory tplf trudeau trump turk turkey turkish unhcr unicef union united unsc yemen youtube"," ")[[1]]
stop_model_opt <- strsplit("allow blame center create desparate eastern enter immigration international fake fascist home island journalist leave life live love open opened opened photo political poor propaganda racist safe save stay tear western"," ")[[1]]
stop_cust <- c(stop_uninformative,stop_ne,stop_model_opt)
# --------------------------------------------------------
# ------------------- Process greece data ----------------
# --------------------------------------------------------
?textProcessor
processed_greece = textProcessor(df_greece$text_stm, metadata = df_greece,
lowercase = FALSE,
removestopwords = FALSE,
removenumbers = FALSE,
removepunctuation = FALSE,
ucp = FALSE,
stem = FALSE,
customstopwords = stop_cust)
# Prepare Docs
?plotRemoved
rows <- nrow(df_greece)
plotRemoved(processed_greece$documents,
lower.thresh = seq(as.integer(0.001*rows),
as.integer(0.05*rows)))
?prepDocuments
out_greece <- prepDocuments(processed_greece$documents,
processed_greece$vocab,
processed_greece$meta,
lower.thresh = 0.005*rows,
upper.thresh = 0.5*rows)
# --------------------------------------------------------
# ------------------- Process channel data ----------------
# --------------------------------------------------------
processed_channel = textProcessor(df_channel$text_stm, metadata = df_channel,
lowercase = FALSE,
removestopwords = FALSE,
removenumbers = FALSE,
removepunctuation = FALSE,
ucp = FALSE,
stem = FALSE,
customstopwords = stop_cust)
# Prepare Docs
rows <- nrow(df_channel)
plotRemoved(processed_channel$documents,
lower.thresh = seq(as.integer(0.001*rows),
as.integer(0.05*rows)))
out_channel <- prepDocuments(processed_channel$documents,
processed_channel$vocab,
processed_channel$meta,
lower.thresh = 0.005*rows,
upper.thresh = 0.5*rows)
# --------------------------------------------------------
# ------------------- Process tigray data ----------------
# --------------------------------------------------------
?textProcessor
processed_tigray = textProcessor(df_tigray$text_stm, metadata = df_tigray,
lowercase = FALSE,
removestopwords = FALSE,
removenumbers = FALSE,
removepunctuation = FALSE,
ucp = FALSE,
stem = FALSE,
customstopwords = stop_cust)
# Prepare Docs
?plotRemoved
rows <- nrow(df_tigray)
plotRemoved(processed_tigray$documents,
lower.thresh = seq(as.integer(0.001*rows),
as.integer(0.05*rows)))
?prepDocuments
out_tigray <- prepDocuments(processed_tigray$documents,
processed_tigray$vocab,
processed_tigray$meta,
lower.thresh = 0.005*rows,
upper.thresh = 0.5*rows)
# --------------------------------------------------------
# ------------------- Process rohingya data --------------
# --------------------------------------------------------
?textProcessor
processed_rohingya = textProcessor(df_rohingya$text_stm, metadata = df_rohingya,
lowercase = FALSE,
removestopwords = FALSE,
removenumbers = FALSE,
removepunctuation = FALSE,
ucp = FALSE,
stem = FALSE,
customstopwords = stop_cust)
# Prepare Docs
?plotRemoved
rows <- nrow(df_rohingya)
plotRemoved(processed_rohingya$documents,
lower.thresh = seq(as.integer(0.001*rows),
as.integer(0.05*rows)))
?prepDocuments
out_rohingya <- prepDocuments(processed_rohingya$documents,
processed_rohingya$vocab,
processed_rohingya$meta,
lower.thresh = 0.005*rows,
upper.thresh = 0.5*rows)
storage_greece <- searchK(documents = out_greece$documents,
vocab = out_greece$vocab,
K = c(3,4,5,6,8,10,12,15,20,25,30,40,50,75,100),
prevalence =~ entity + s(day),
data = out_greece$meta,
max.em.its = 25,
seed = 42)
plot(storage_greece) # -> 7/8 seems to be good
#exclusivity(model_fit, M = 10)
# --------------------------------------------------------
# ------------------- Find k for channel ------------------
# --------------------------------------------------------
# Find best K (use this code to train stm for different K's)
storage_channel <- searchK(documents = out_channel$documents,
vocab = out_channel$vocab,
K = c(3,4,5,6,8,10,12,15,20,25,30,40,50,75,100),
prevalence =~ entity + s(day),
data = out_channel$meta,
max.em.its = 25,
seed = 42)
plot(storage_greece)
storage_greece$results$semcoh
storage_greece$results$exclus
storage_greece$results$semcoh
model_greece_4 <- stm(documents = out_greece$documents,
vocab = out_greece$vocab,
K = 4,
prevalence =~ entity + s(day),
data = out_greece$meta,
init.type = "Spectral",
seed = 42)
model_greece_5 <- stm(documents = out_greece$documents,
vocab = out_greece$vocab,
K = 5,
prevalence =~ entity + s(day),
data = out_greece$meta,
init.type = "Spectral",
seed = 42)
model_greece_4 <- stm(documents = out_greece$documents,
vocab = out_greece$vocab,
K = 4,
prevalence =~ entity + s(day),
data = out_greece$meta,
init.type = "Spectral",
max.em.its = 15,
seed = 42)
model_greece_5 <- stm(documents = out_greece$documents,
vocab = out_greece$vocab,
K = 5,
prevalence =~ entity + s(day),
data = out_greece$meta,
init.type = "Spectral",
max.em.its = 15,
seed = 42)
model_greece_6 <- stm(documents = out_greece$documents,
vocab = out_greece$vocab,
K = 6,
prevalence =~ entity + s(day),
data = out_greece$meta,
init.type = "Spectral",
max.em.its = 15,
seed = 42)
model_greece <- model_greece_4
# Plot the convergence
plot(model_greece$convergence$bound,
type = "l",
ylab = "Approximate Convergence",
main = "Convergence")
labelTopics(model = model_greece,
n = 10)
# Plot frequency of topics
plot(model_greece, type="summary", label="frex")
# Plot topic correlations
mod.out.corr <-topicCorr(model_greece)
plot(mod.out.corr)
?toLDAvis
toLDAvis(model_greece, docs = out_greece$documents)
model_greece <- model_greece_6
# Plot the convergence
plot(model_greece$convergence$bound,
type = "l",
ylab = "Approximate Convergence",
main = "Convergence")
labelTopics(model = model_greece,
n = 10)
# Plot frequency of topics
plot(model_greece, type="summary", label="frex")
# Plot topic correlations
mod.out.corr <-topicCorr(model_greece)
plot(mod.out.corr)
?toLDAvis
toLDAvis(model_greece, docs = out_greece$documents)
model_greece <- model_greece_5
# Plot the convergence
plot(model_greece$convergence$bound,
type = "l",
ylab = "Approximate Convergence",
main = "Convergence")
labelTopics(model = model_greece,
n = 10)
# Plot frequency of topics
plot(model_greece, type="summary", label="frex")
# Plot topic correlations
mod.out.corr <-topicCorr(model_greece)
plot(mod.out.corr)
?toLDAvis
toLDAvis(model_greece, docs = out_greece$documents)
labelTopics(model = model_greece,
n = 10)
out_greece$vocab
stop_uninformative <- strsplit("able absolutely access according account accountable across action actually affected agency agree agreement alive allegation allow allowed allowing almost alone along already also always ambassador amid among another answer anti anymore anyone anything area arent around arrived article asylum attempt attention away back based basic become believe best better black blame blocked born breaking bring brother build call called calling came cant case caught cause centre change claim claiming clear clearly close come coming comment commited commiting completely concern concerned condemn condition confirmed  continue continues could country course cover created credible crisis currently daily day deal dear decade decision demand department despite didnt difference different dire doesnt done dont east eastern easy either effort else endf enough especially ethnic even ever every everyone everything evidence evil exactly expect extremely face facility facing fact failed fake false federal feel find first found four forget free fuck fucking full genuine getting given giving great ground group happy imagine including issue instead isnt give going good half hand happen happened happening hard head heading held high horn hour however huge idea image immediate immediately independent information inside internal internally interview investigate investigation issue join journalist keep kind know known lack land landing largest last latest leader least left let letting level lie like likely little live living load local long longer look looking lost made mail major majority make making many massive matter maybe mean medium member middle might migration mind month morning mostly move much must name national near nearly need needed neighboring never news next nobody north northern nothing obviously office official one ongoing operation others paid part party pas past people perhaps person place plan please point post press prevails prime probably problem process programme provide public push putting question quite rather reach read real realise reality really reason received recent record remains remember report reported reporting resident response responsible rest result right said satellite say saying second seek seeker seeking seem seems seen send sending sent series service several shame share shit show side simple simply since single site situation small someone something soon sorry sort south source speak special spread stand star start started statement street still stop stopped stopping story stupid sure surely system take taken taking talk talking tell term testimony thank thanks thats there theyre thing think though thought three time today told took torn towards town tried true truth trying turn tweet understand unless urgent urgently used using video vice view virus visit voice wait waiting want wanted watch water week welcome well west western withdraw within without whats whilst white whole wing wish wonder wont word world worse wrong would year yesterday young youre"," ")[[1]]
stop_ne <- strsplit("abiy addis aegean afewerki afeworki afghan afghanistan africa african america amnesty ahmed american amhara andrew ankara antony arab asean asia assad aung bachelet balukhali bangladesh bangladeshi biden blinken boris borisjohnson borrell brexit brit britain british brussels bulgaria burma burmese calais canada channel china commission commissioner corona coronavirus council covid cox dover dublin edirne england english erdoan erdogan eritrea eritrean ethiopia ethiopian euro europe european evros farage filippo fontelles france french freya_cole garneau geneva german germany grandi greece greek guterres haavisto hamdayet harris hindu hitsats houthi houthis idlib idp india indian iran iraq isaias isayas isi israel italy jammu jazeera jerry johnson josep junta justin kachin kadra karen kayin kamala kent kenya kurd labour linda lindat_g lebanon lesbos lesvos libya london maikadra manipur marc merkel michelle mizoram moria muslim mutraw myanmar nation nations nationshumanrights nato nazi nigel november oromia oromo pakistan patel president priti putin reuters rohingya rohingyas russia russian samri secretary shimelba shire somalia spain state sudan sudanese syria syrian tegaru tigrai tigrayan tigrayans thai thailand tory tplf trudeau trump turk turkey turkish unhcr unicef union united unsc yemen youtube"," ")[[1]]
stop_model_opt <- strsplit("accept allow blame border center closed create cross desparate eastern enter immigration international fake fascist home hundred illegal illegally island journalist leave legal legally life live love million open opened opened photo political poor propaganda racist safe save stay tear thousand western"," ")[[1]]
stop_cust <- c(stop_uninformative,stop_ne,stop_model_opt)
processed_greece = textProcessor(df_greece$text_stm, metadata = df_greece,
lowercase = FALSE,
removestopwords = FALSE,
removenumbers = FALSE,
removepunctuation = FALSE,
ucp = FALSE,
stem = FALSE,
customstopwords = stop_cust)
# Prepare Docs
?plotRemoved
rows <- nrow(df_greece)
plotRemoved(processed_greece$documents,
lower.thresh = seq(as.integer(0.001*rows),
as.integer(0.05*rows)))
1+1
1+2
rows <- nrow(df_greece)
plotRemoved(processed_greece$documents,
lower.thresh = seq(as.integer(0.001*rows),
as.integer(0.05*rows)))
out_greece <- prepDocuments(processed_greece$documents,
processed_greece$vocab,
processed_greece$meta,
lower.thresh = 0.005*rows,
upper.thresh = 0.5*rows)
model_greece_4
out_greece$vocab
knitr::opts_chunk$set(echo = TRUE)
model_greece_6 <- stm(documents = out_greece$documents,
vocab = out_greece$vocab,
K = 6,
prevalence =~ entity + s(day),
data = out_greece$meta,
init.type = "Spectral",
max.em.its = 15,
seed = 42)
library(stm)
model_greece_6 <- stm(documents = out_greece$documents,
vocab = out_greece$vocab,
K = 6,
prevalence =~ entity + s(day),
data = out_greece$meta,
init.type = "Spectral",
max.em.its = 15,
seed = 42)
model_greece <- model_greece_5
# Plot the convergence
plot(model_greece$convergence$bound,
type = "l",
ylab = "Approximate Convergence",
main = "Convergence")
model_greece <- model_greece_6
# Plot the convergence
plot(model_greece$convergence$bound,
type = "l",
ylab = "Approximate Convergence",
main = "Convergence")
n = 10)
labelTopics(model = model_greece,
n = 10)
toLDAvis(model_greece, docs = out_greece$documents)
processed_greece = textProcessor(df_greece$text_stm, metadata = df_greece,
lowercase = FALSE,
removestopwords = FALSE,
removenumbers = FALSE,
removepunctuation = FALSE,
ucp = FALSE,
stem = FALSE,
customstopwords = stop_ne)
# Prepare Docs
?plotRemoved
rows <- nrow(df_greece)
plotRemoved(processed_greece$documents,
lower.thresh = seq(as.integer(0.001*rows),
as.integer(0.05*rows)))
?prepDocuments
out_greece <- prepDocuments(processed_greece$documents,
processed_greece$vocab,
processed_greece$meta,
lower.thresh = 0.005*rows,
upper.thresh = 0.5*rows)
model_greece_6 <- stm(documents = out_greece$documents,
vocab = out_greece$vocab,
K = 6,
prevalence =~ entity + s(day),
data = out_greece$meta,
init.type = "Spectral",
max.em.its = 15,
seed = 42)
labelTopics(model = model_greece,
n = 10)
toLDAvis(model_greece, docs = out_greece$documents)
