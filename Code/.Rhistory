model_tigray <- model_tigray_6
plot(model_tigray$convergence$bound,
type = "l",
ylab = "Approximate Convergence",
main = "Convergence")
# Label Topics
?labelTopics
labelTopics(model = model_tigray,
n = 10)
# Plot frequency of topics
plot(model_tigray, type="summary")
# Plot topic correlations
mod.out.corr <-topicCorr(model_tigray)
plot(mod.out.corr)
?toLDAvis
toLDAvis(model_tigray, docs = out_tigray$documents)
# # Plot the model
# ?plot.STM
# plot.STM(x = model_greece,
#          type = "labels",
#          n = 10)
# # Find thougths
# ?findThoughts # shows documents that are highly associated with a topic
# findThoughts(model = model_greece,
#              texts = out_greece$meta$text_coherent)
# # Plot expected distribution of topic proportions
# plot(model_greece, type="hist")
#
# # Plot wordcloud of a topic
# cloud(model_greece, topic = 1)
#
# plot(prep_greece, "date", method="continuous", topics = 5, model = model_greece)
labelTopics(model = model_tigray,
n = 10)
model_tigray <- model_tigray_7
# Plot the convergence
plot(model_tigray$convergence$bound,
type = "l",
ylab = "Approximate Convergence",
main = "Convergence")
# Label Topics
?labelTopics
labelTopics(model = model_tigray,
n = 10)
# Plot frequency of topics
plot(model_tigray, type="summary")
# Plot topic correlations
mod.out.corr <-topicCorr(model_tigray)
plot(mod.out.corr)
?toLDAvis
toLDAvis(model_tigray, docs = out_tigray$documents)
# # Plot the model
# ?plot.STM
# plot.STM(x = model_greece,
#          type = "labels",
#          n = 10)
# # Find thougths
# ?findThoughts # shows documents that are highly associated with a topic
# findThoughts(model = model_greece,
#              texts = out_greece$meta$text_coherent)
# # Plot expected distribution of topic proportions
# plot(model_greece, type="hist")
#
# # Plot wordcloud of a topic
# cloud(model_greece, topic = 1)
#
# plot(prep_greece, "date", method="continuous", topics = 5, model = model_greece)
labelTopics(model = model_tigray,
n = 10)
model_tigray <- model_tigray_8
# Plot the convergence
plot(model_tigray$convergence$bound,
type = "l",
ylab = "Approximate Convergence",
main = "Convergence")
# Label Topics
?labelTopics
labelTopics(model = model_tigray,
n = 10)
# Plot frequency of topics
plot(model_tigray, type="summary")
# Plot topic correlations
mod.out.corr <-topicCorr(model_tigray)
plot(mod.out.corr)
?toLDAvis
toLDAvis(model_tigray, docs = out_tigray$documents)
# # Plot the model
# ?plot.STM
# plot.STM(x = model_greece,
#          type = "labels",
#          n = 10)
# # Find thougths
# ?findThoughts # shows documents that are highly associated with a topic
# findThoughts(model = model_greece,
#              texts = out_greece$meta$text_coherent)
# # Plot expected distribution of topic proportions
# plot(model_greece, type="hist")
#
# # Plot wordcloud of a topic
# cloud(model_greece, topic = 1)
#
# plot(prep_greece, "date", method="continuous", topics = 5, model = model_greece)
labelTopics(model = model_tigray,
n = 10)
storage_rohingya <- searchK(documents = out_rohingya$documents,
vocab = out_rohingya$vocab,
K = c(4,5,6,7,8,9,10,11,12),
prevalence =~ entity + s(day),
data = out_rohingya$meta,
max.em.its = 25,
seed = 42)
plot(storage_rohingya)
plot(storage_rohingya)
model_rohingya_6 <- stm(documents = out_rohingya$documents,
vocab = out_rohingya$vocab,
K = 6,
prevalence =~ entity + s(day),
data = out_rohingya$meta,
init.type = "Spectral",
seed = 42)
model_rohingya_8 <- stm(documents = out_rohingya$documents,
vocab = out_rohingya$vocab,
K = 8,
prevalence =~ entity + s(day),
data = out_rohingya$meta,
init.type = "Spectral",
seed = 42)
model_rohingya_9 <- stm(documents = out_rohingya$documents,
vocab = out_rohingya$vocab,
K = 9,
prevalence =~ entity + s(day),
data = out_rohingya$meta,
init.type = "Spectral",
seed = 42)
model_rohingya <- model_rohingya_6
# Plot the convergence
plot(model_rohingya$convergence$bound,
type = "l",
ylab = "Approximate Convergence",
main = "Convergence")
# Label Topics
?labelTopics
labelTopics(model = model_rohingya,
n = 6)
# Plot frequency of topics
plot(model_rohingya, type="summary")
# Plot topic correlations
mod.out.corr <-topicCorr(model_rohingya)
plot(mod.out.corr)
?toLDAvis
toLDAvis(model_rohingya, docs = out_rohingya$documents)
# # Plot the model
# ?plot.STM
# plot.STM(x = model_greece,
#          type = "labels",
#          n = 10)
# # Find thougths
# ?findThoughts # shows documents that are highly associated with a topic
# findThoughts(model = model_greece,
#              texts = out_greece$meta$text_coherent)
# # Plot expected distribution of topic proportions
# plot(model_greece, type="hist")
#
# # Plot wordcloud of a topic
# cloud(model_greece, topic = 1)
#
# plot(prep_greece, "date", method="continuous", topics = 5, model = model_greece)
labelTopics(model = model_rohingya,
n = 6)
model_rohingya <- model_rohingya_8
# Plot the convergence
plot(model_rohingya$convergence$bound,
type = "l",
ylab = "Approximate Convergence",
main = "Convergence")
# Label Topics
?labelTopics
labelTopics(model = model_rohingya,
n = 6)
# Plot frequency of topics
plot(model_rohingya, type="summary")
# Plot topic correlations
mod.out.corr <-topicCorr(model_rohingya)
plot(mod.out.corr)
?toLDAvis
toLDAvis(model_rohingya, docs = out_rohingya$documents)
# # Plot the model
# ?plot.STM
# plot.STM(x = model_greece,
#          type = "labels",
#          n = 10)
# # Find thougths
# ?findThoughts # shows documents that are highly associated with a topic
# findThoughts(model = model_greece,
#              texts = out_greece$meta$text_coherent)
# # Plot expected distribution of topic proportions
# plot(model_greece, type="hist")
#
# # Plot wordcloud of a topic
# cloud(model_greece, topic = 1)
#
# plot(prep_greece, "date", method="continuous", topics = 5, model = model_greece)
labelTopics(model = model_rohingya,
n = 6)
model_rohingya <- model_rohingya_9
# Plot the convergence
plot(model_rohingya$convergence$bound,
type = "l",
ylab = "Approximate Convergence",
main = "Convergence")
# Label Topics
?labelTopics
labelTopics(model = model_rohingya,
n = 6)
# Plot frequency of topics
plot(model_rohingya, type="summary")
# Plot topic correlations
mod.out.corr <-topicCorr(model_rohingya)
plot(mod.out.corr)
?toLDAvis
toLDAvis(model_rohingya, docs = out_rohingya$documents)
# # Plot the model
# ?plot.STM
# plot.STM(x = model_greece,
#          type = "labels",
#          n = 10)
# # Find thougths
# ?findThoughts # shows documents that are highly associated with a topic
# findThoughts(model = model_greece,
#              texts = out_greece$meta$text_coherent)
# # Plot expected distribution of topic proportions
# plot(model_greece, type="hist")
#
# # Plot wordcloud of a topic
# cloud(model_greece, topic = 1)
#
# plot(prep_greece, "date", method="continuous", topics = 5, model = model_greece)
labelTopics(model = model_rohingya,
n = 6)
model_rohingya <- model_rohingya_6
plot(prep_rohingya, covariate = "entity", topics = c(1,2,3,4,5,6),
model = model_rohingya, method = "difference",
cov.value1 = "Refugee", cov.value2 = "Migrant",
xlab = "Refugee ... Migrant",
main = "Effect of tweets containing refugee vs migrants",
xlim = c(-0.1, 0.1),
labeltype = "custom",
custom.labels = c("Topic1","Topic2","Topic3","Topic4","Topic5","Topic6"))
out_rohingya$meta$entity <- as.factor(out_rohingya$meta$entity)
prep_rohingya <- estimateEffect(1:6 ~ entity + s(day), model_rohingya, meta = out_rohingya$meta, uncertainty = "None")
plot(prep_rohingya, covariate = "entity", topics = c(1,2,3,4,5,6),
model = model_rohingya, method = "difference",
cov.value1 = "Refugee", cov.value2 = "Migrant",
xlab = "Refugee ... Migrant",
main = "Effect of tweets containing refugee vs migrants",
xlim = c(-0.1, 0.1),
labeltype = "custom",
custom.labels = c("Topic1","Topic2","Topic3","Topic4","Topic5","Topic6"))
plot(prep_rohingya, covariate = "entity", topics = c(1,2,3,4,5,6),
model = model_rohingya, method = "difference",
cov.value1 = "Refugee", cov.value2 = "Migrant",
xlab = "Refugee ... Migrant",
main = "Effect of tweets containing refugee vs migrants",
xlim = c(-0.2, 0.2),
labeltype = "custom",
custom.labels = c("Topic1","Topic2","Topic3","Topic4","Topic5","Topic6"))
labelTopics(model = model_rohingya,
n = 6)
plot(storage_greece)
plot(storage_tigray)
plot(storage_rohingya)
model_greece <- model_greece_6
labelTopics(model = model_greece,
n = 10)
model_greece <- model_greece_7
labelTopics(model = model_greece,
n = 10)
?labelTopics
labelTopics(model = model_greece,
n = 10)
model_greece <- model_greece_8
labelTopics(model = model_greece,
n = 10)
model_greece <- model_greece_6
labelTopics(model = model_greece,
n = 10)
model_greece_5 <- stm(documents = out_greece$documents,
vocab = out_greece$vocab,
K = 5,
prevalence =~ entity + s(day),
data = out_greece$meta,
init.type = "Spectral",
seed = 42)
stop_uninformative <- strsplit("according across agreement already also always another anyone around asylum back become breaking came cant case caught cause centre close come condition continue continues could created crisis day deal done dont east enough even every everyone facing first including instead give going good happening head held high huge keep know largest last least left like long longer look made make many maybe mean medium member middle month move much must near need never news next north nothing part people place please problem push reach read really remains report said say saying seeker seen send sending sent series several show side since situation south stand still sure take taken taking talk tell thats thing think time today told took towards true trying turn urgent urgently used using video vice want week well west without whats world would year yesterday"," ")[[1]]
stop_ne <- strsplit("abiy afghan afghanistan africa ahmed amhara andrew ankara antony asean asia assad aung balukhali bangladesh bangladeshi biden blinken borrell bulgaria burma burmese china corona coronavirus covid cox erdogan eritrea eritrean ethiopia ethiopian euro european evros filippo fontelles france freya_cole geneva german germany grandi guterres harris hindu hitsats idlib india indian iran iraq isaias isi italy jammu josep junta justin kachin karen kayin kamala lindat_g lebanon lesbos lesvos libya manipur merkel mizoram moria muslim mutraw myanmar nations nato pakistan president putin rohingya rohingyas russia russian secretary shimelba state sudan sudanese tigrai tigrayan tigrayans thai thailand tplf trudeau trump turk unhcr unicef union united unsc"," ")[[1]]
stop_cust <- c(stop_uninformative,stop_ne)
processed_greece = textProcessor(df_greece$text_stm, metadata = df_greece,
lowercase = FALSE,
removestopwords = FALSE,
removenumbers = FALSE,
removepunctuation = FALSE,
ucp = FALSE,
stem = FALSE,
customstopwords = stop_cust)
processed_greece = textProcessor(df_greece$text_stm, metadata = df_greece,
lowercase = FALSE,
removestopwords = FALSE,
removenumbers = FALSE,
removepunctuation = FALSE,
ucp = FALSE,
stem = FALSE,
customstopwords = stop_cust)
out_greece <- prepDocuments(processed_greece$documents,
processed_greece$vocab,
processed_greece$meta,
lower.thresh = 1000,
upper.thresh = 0.5*rows)
model_greece_8 <- stm(documents = out_greece$documents,
vocab = out_greece$vocab,
K = 8,
prevalence =~ entity + s(day),
data = out_greece$meta,
init.type = "Spectral",
seed = 42)
plot(model_greece$convergence$bound,
type = "l",
ylab = "Approximate Convergence",
main = "Convergence")
model_greece <- model_greece_8
plot(model_greece$convergence$bound,
type = "l",
ylab = "Approximate Convergence",
main = "Convergence")
# Label Topics
?labelTopics
labelTopics(model = model_greece,
n = 10)
# Plot frequency of topics
plot(model_greece, type="summary")
# Plot topic correlations
mod.out.corr <-topicCorr(model_greece)
plot(mod.out.corr)
?toLDAvis
toLDAvis(model_greece, docs = out_greece$documents)
# # Plot the model
# ?plot.STM
# plot.STM(x = model_greece,
#          type = "labels",
#          n = 10)
# # Find thougths
# ?findThoughts # shows documents that are highly associated with a topic
# findThoughts(model = model_greece,
#              texts = out_greece$meta$text_coherent)
# # Plot expected distribution of topic proportions
# plot(model_greece, type="hist")
#
# # Plot wordcloud of a topic
# cloud(model_greece, topic = 1)
#
# plot(prep_greece, "date", method="continuous", topics = 5, model = model_greece)
labelTopics(model = model_greece,
n = 10)
mod.out.corr <-topicCorr(model_greece)
plot(mod.out.corr)
stop_uninformative <- strsplit("according across agreement already also always another anyone around asylum back become breaking came cant case caught cause centre close come condition continue continues could created crisis day deal done dont east enough even every everyone facing first including instead give going good happening head held high huge keep know largest last least left like long longer look made make many maybe mean medium member middle month move much must near need never news next north nothing part people place please problem push reach read really remains report said say saying seeker seen send sending sent series several show side since situation south stand still sure take taken taking talk tell thats thing think time today told took towards true trying turn urgent urgently used using video vice virus want week well west without whats world would year yesterday"," ")[[1]]
stop_ne <- strsplit("abiy afghan afghanistan africa ahmed amhara andrew ankara antony asean asia assad aung balukhali bangladesh bangladeshi biden blinken borrell bulgaria burma burmese china corona coronavirus covid cox erdogan eritrea eritrean ethiopia ethiopian euro european evros filippo fontelles france freya_cole geneva german germany grandi guterres harris hindu hitsats idlib india indian iran iraq isaias isi italy jammu josep junta justin kachin karen kayin kamala lindat_g lebanon lesbos lesvos libya manipur merkel mizoram moria muslim mutraw myanmar nation nations nato pakistan president putin rohingya rohingyas russia russian secretary shimelba state sudan sudanese tigrai tigrayan tigrayans thai thailand tplf trudeau trump turk unhcr unicef union united unsc"," ")[[1]]
stop_cust <- c(stop_uninformative,stop_ne)
stop_uninformative <- strsplit("according across agreement already also always another anyone around asylum back become breaking came cant case caught cause centre close come condition continue continues could created crisis day deal done dont east enough even every everyone facing first including instead give going good happening head held high huge keep know largest last least left like long longer look made make many maybe mean medium member middle month move much must near need never news next north nothing part people place please problem push reach read really remains report said say saying seeker seen send sending sent series several show side since situation south stand still sure take taken taking talk tell thats thing think time today told took towards true trying turn urgent urgently used using video vice virus want week well west without whats world would year yesterday"," ")[[1]]
stop_ne <- strsplit("abiy afghan afghanistan africa ahmed amhara andrew ankara antony asean asia assad aung balukhali bangladesh bangladeshi biden blinken borrell bulgaria burma burmese china corona coronavirus covid cox erdogan eritrea eritrean ethiopia ethiopian euro european evros filippo fontelles france freya_cole geneva german germany grandi guterres harris hindu hitsats idlib india indian iran iraq isaias isi italy jammu josep junta justin kachin karen kayin kamala lindat_g lebanon lesbos lesvos libya manipur merkel mizoram moria muslim mutraw myanmar nation nations nato pakistan president putin rohingya rohingyas russia russian secretary shimelba state sudan sudanese tigrai tigrayan tigrayans thai thailand tplf trudeau trump turk unhcr unicef union united unsc"," ")[[1]]
stop_cust <- c(stop_uninformative,stop_ne)
processed_greece = textProcessor(df_greece$text_stm, metadata = df_greece,
lowercase = FALSE,
removestopwords = FALSE,
removenumbers = FALSE,
removepunctuation = FALSE,
ucp = FALSE,
stem = FALSE,
customstopwords = stop_cust)
processed_greece = textProcessor(df_greece$text_stm, metadata = df_greece,
lowercase = FALSE,
removestopwords = FALSE,
removenumbers = FALSE,
removepunctuation = FALSE,
ucp = FALSE,
stem = FALSE,
customstopwords = stop_cust)
out_greece <- prepDocuments(processed_greece$documents,
processed_greece$vocab,
processed_greece$meta,
lower.thresh = 1000,
upper.thresh = 0.5*rows)
processed_tigray = textProcessor(df_tigray$text_stm, metadata = df_tigray,
lowercase = FALSE,
removestopwords = FALSE,
removenumbers = FALSE,
removepunctuation = FALSE,
ucp = FALSE,
stem = FALSE,
customstopwords = stop_cust)
out_tigray <- prepDocuments(processed_tigray$documents,
processed_tigray$vocab,
processed_tigray$meta,
lower.thresh = 200,
upper.thresh = 0.5*rows)
processed_rohingya = textProcessor(df_rohingya$text_stm, metadata = df_rohingya,
lowercase = FALSE,
removestopwords = FALSE,
removenumbers = FALSE,
removepunctuation = FALSE,
ucp = FALSE,
stem = FALSE,
customstopwords = stop_cust)
out_rohingya <- prepDocuments(processed_rohingya$documents,
processed_rohingya$vocab,
processed_rohingya$meta,
lower.thresh = 200,
upper.thresh = 0.5*rows)
storage_greece <- searchK(documents = out_greece$documents,
vocab = out_greece$vocab,
K = c(4,6,8,10,12,15,20,25,30,40,50),
prevalence =~ entity + s(day),
data = out_greece$meta,
max.em.its = 50,
seed = 42)
storage_greece <- searchK(documents = out_greece$documents,
vocab = out_greece$vocab,
K = c(4,6,8,10,12,15,20,25,30,40,50),
prevalence =~ entity + s(day),
data = out_greece$meta,
max.em.its = 50,
seed = 42)
storage_tigray <- searchK(documents = out_tigray$documents,
vocab = out_tigray$vocab,
K = c(4,6,8,10,12,15,20,25,30,40,50),
prevalence =~ entity + s(day),
data = out_tigray$meta,
max.em.its = 50,
seed = 42)
storage_rohingya <- searchK(documents = out_rohingya$documents,
vocab = out_rohingya$vocab,
K = c(4,6,8,10,12,15,20,25,30,40,50),
prevalence =~ entity + s(day),
data = out_rohingya$meta,
max.em.its = 50,
seed = 42)
plot(storage_greece)
plot(storage_tigray)
plot(storage_rohingya)
plot(storage_greece)
storage_greece$results$exclus
model_greece_40 <- stm(documents = out_greece$documents,
vocab = out_greece$vocab,
K = 40,
prevalence =~ entity + s(day),
data = out_greece$meta,
init.type = "Spectral",
seed = 42)
model_greece <- model_greece_40
# Plot the convergence
plot(model_greece$convergence$bound,
type = "l",
ylab = "Approximate Convergence",
main = "Convergence")
labelTopics(model = model_greece,
n = 10)
plot(model_greece, type="summary")
mod.out.corr <-topicCorr(model_greece)
plot(mod.out.corr)
toLDAvis(model_greece, docs = out_greece$documents)
plot(storage_greece)
model_greece <- model_greece_6
plot(model_greece$convergence$bound,
type = "l",
ylab = "Approximate Convergence",
main = "Convergence")
model_greece_6 <- stm(documents = out_greece$documents,
vocab = out_greece$vocab,
K = 6,
prevalence =~ entity + s(day),
data = out_greece$meta,
init.type = "Spectral",
seed = 42)
model_greece <- model_greece_6
plot(model_greece$convergence$bound,
type = "l",
ylab = "Approximate Convergence",
main = "Convergence")
labelTopics(model = model_greece,
n = 10)
# Plot frequency of topics
plot(model_greece, type="summary")
# Plot topic correlations
mod.out.corr <-topicCorr(model_greece)
plot(mod.out.corr)
?toLDAvis
toLDAvis(model_greece, docs = out_greece$documents)
storage_greece$results$semcoh
toLDAvis(model_greece, docs = out_greece$documents)
model_greece_7 <- stm(documents = out_greece$documents,
vocab = out_greece$vocab,
K = 7,
prevalence =~ entity + s(day),
data = out_greece$meta,
init.type = "Spectral",
seed = 42)
model_greece_8 <- stm(documents = out_greece$documents,
vocab = out_greece$vocab,
K = 8,
prevalence =~ entity + s(day),
data = out_greece$meta,
init.type = "Spectral",
seed = 42)
