{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings training\n",
    "\n",
    "**Required files:**\n",
    " - event_df_clean = event specific dataframe with preprocessed text, use column 'text_coherent' for training\n",
    " - event_cands_merged = dataframe of candidates that are merged after 1st step\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import relevant packages for the following parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading english - 1grams ...\n",
      "Reading english - 1grams ...\n",
      "Reading english - 2grams ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ekphrasis\\classes\\exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
      "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n"
     ]
    }
   ],
   "source": [
    "#python libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import gensim\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# self written modules\n",
    "import preprocessing\n",
    "\n",
    "# storing python objects in the desired locations using pickle\n",
    "import pickle\n",
    "\n",
    "def pickle_file(file_name, file_to_dump):\n",
    "    directory_path = os.getcwd() + \"/../../../../\"\n",
    "    folder_name = file_name.split('_')[0]\n",
    "    file_path = directory_path +  fr\"Dropbox (CBS)/Master thesis data/Candidate Data/{folder_name}/{file_name}\"\n",
    "    with open(file_path, 'wb') as fp:\n",
    "        pickle.dump(file_to_dump, fp)\n",
    "\n",
    "def load_pickle(file_name):\n",
    "    directory_path = os.getcwd() + \"/../../../../\"\n",
    "    folder_name = file_name.split('_')[0]\n",
    "    file_path = directory_path + fr\"Dropbox (CBS)/Master thesis data/Candidate Data/{folder_name}/{file_name}\"\n",
    "    with open(file_path, \"rb\") as input_file:\n",
    "        return pickle.load(input_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 22966 tweets!\n"
     ]
    }
   ],
   "source": [
    "tigray_url = r\"Dropbox (CBS)/Master thesis data/Event Dataframes/Clean/df_tigray_clean.csv\" # location of Tigray dataset\n",
    "greece_url = r\"Dropbox (CBS)/Master thesis data/Event Dataframes/Clean/df_greece_clean.csv\" # location of Greece dataset\n",
    "rohingya_url = r\"Dropbox (CBS)/Master thesis data/Event Dataframes/Clean/df_rohingya_clean.csv\" # location of Rohingya dataset\n",
    "all_url = r\"Dropbox (CBS)/Master thesis data/df_tweets.csv\" # for all tweets\n",
    "\n",
    "def read_event_df(data_url):\n",
    "    directory_path = os.getcwd() + \"/../../../../\" + data_url \n",
    "    event_df = pd.read_csv(directory_path, index_col=0)\n",
    "    event_df.reset_index(drop=True, inplace=True)\n",
    "    print(f'loaded {event_df.shape[0]} tweets!')\n",
    "    return event_df\n",
    "\n",
    "# pick the df \n",
    "event_df = read_event_df(rohingya_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets at the start: 22966\n",
      "Tweets after 100% duplicates removed: 22956\n",
      "calculating similarities across documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1787it [00:00, 17695.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity calculation completed in 57.66400074958801 seconds\n",
      "removing fuzzy duplicates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47992it [00:01, 24982.97it/s]\n",
      "C:\\Users\\nikodemicek\\Documents\\GitHub\\refugee_project\\Code\\preprocessing.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dupl_removed['is_dup'][i] = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20017 tweets left after 70.0% similar tweets (by cosine similarity) removed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>author_id</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>...</th>\n",
       "      <th>migrant</th>\n",
       "      <th>immigrant</th>\n",
       "      <th>asylum_seeker</th>\n",
       "      <th>other</th>\n",
       "      <th>text_coherent</th>\n",
       "      <th>retweet_count_sum</th>\n",
       "      <th>count</th>\n",
       "      <th>text_alphanum</th>\n",
       "      <th>text_stm</th>\n",
       "      <th>is_dup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>For #Rohingya Survivors in Bangladesh, Artwork...</td>\n",
       "      <td>en</td>\n",
       "      <td>1373792416126402560</td>\n",
       "      <td>2021-03-22 00:23:30+00:00</td>\n",
       "      <td>77844813</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>For rohingya Survivors in Bangladesh, Artwork ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>for rohingya survivors in bangladesh artwork b...</td>\n",
       "      <td>rohingya survivor bangladesh artwork bear witn...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dlvr.it</td>\n",
       "      <td>AstraZeneca dispels Indonesian Muslim concerns...</td>\n",
       "      <td>en</td>\n",
       "      <td>1373800977778700288</td>\n",
       "      <td>2021-03-22 00:57:31+00:00</td>\n",
       "      <td>1898083759</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>AstraZeneca dispels Indonesian Muslim concerns...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>astrazeneca dispels indonesian muslim concerns...</td>\n",
       "      <td>astrazeneca dispels indonesian muslim concern ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>@prabha_j @MehHarshil @derekobrienmp I think u...</td>\n",
       "      <td>en</td>\n",
       "      <td>1373802051524730880</td>\n",
       "      <td>2021-03-22 01:01:47+00:00</td>\n",
       "      <td>1209116380257112064</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>I think u are one of the illegally migrant Roh...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>prabhaj mehharshil derekobrienmp i think u are...</td>\n",
       "      <td>think illegally rohingya bangladesh better kee...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>India seals Myanmar border amid strains over r...</td>\n",
       "      <td>en</td>\n",
       "      <td>1373802536579174401</td>\n",
       "      <td>2021-03-22 01:03:43+00:00</td>\n",
       "      <td>1032998054297780224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>India seals Myanmar border amid strains over r...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>india seals myanmar border amid strains over r...</td>\n",
       "      <td>india seal myanmar border amid strain crisis</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Fleeing coup, Myanmar police refugees in India...</td>\n",
       "      <td>en</td>\n",
       "      <td>1373804367757807619</td>\n",
       "      <td>2021-03-22 01:10:59+00:00</td>\n",
       "      <td>15552861</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Fleeing coup, Myanmar police refugees in India...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>fleeing coup myanmar police refugees in india ...</td>\n",
       "      <td>fleeing coup myanmar police india seek asylum ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22961</th>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>they went wedding ceremony of they're uncle th...</td>\n",
       "      <td>en</td>\n",
       "      <td>1388268996110266374</td>\n",
       "      <td>2021-04-30 23:08:16+00:00</td>\n",
       "      <td>1360258667292033028</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>they went wedding ceremony of they' re uncle t...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>they went wedding ceremony of theyre uncle the...</td>\n",
       "      <td>went wedding ceremony uncle enjoyed bamboo bri...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22962</th>\n",
       "      <td>BPbreakingnews</td>\n",
       "      <td>A labour group yesterday called on the governm...</td>\n",
       "      <td>en</td>\n",
       "      <td>1388272686372057088</td>\n",
       "      <td>2021-04-30 23:22:55+00:00</td>\n",
       "      <td>20583561</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>A labour group yesterday called on the governm...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>a labour group yesterday called on the governm...</td>\n",
       "      <td>labour group yesterday called government speed...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22963</th>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>Declare a fly zone right now please. There are...</td>\n",
       "      <td>en</td>\n",
       "      <td>1388273220579741701</td>\n",
       "      <td>2021-04-30 23:25:03+00:00</td>\n",
       "      <td>1360335395939115010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Declare a fly zone right now please . There ar...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>declare a fly zone right now please. there are...</td>\n",
       "      <td>declare zone right please million karen kachim...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22964</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>@lvandenassum MYANMAR MILITARY REGIME IS CHEAT...</td>\n",
       "      <td>en</td>\n",
       "      <td>1388273570539782151</td>\n",
       "      <td>2021-04-30 23:26:26+00:00</td>\n",
       "      <td>973730357051838465</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>MYANMAR MILITARY REGIME IS CHEATING, MANIPULAT...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>lvandenassum myanmar military regime is cheati...</td>\n",
       "      <td>myanmar military regime cheating manipulating ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22965</th>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>The #fire in the #Rohingya refugee #camp leave...</td>\n",
       "      <td>en</td>\n",
       "      <td>1388274549968437250</td>\n",
       "      <td>2021-04-30 23:30:20+00:00</td>\n",
       "      <td>733878114011381760</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>The fire in the rohingya refugee camp leaves 4...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>the fire in the rohingya refugee camp leaves 4...</td>\n",
       "      <td>fire rohingya camp leaf people without shelter...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20017 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    source                                               text  \\\n",
       "0          Twitter Web App  For #Rohingya Survivors in Bangladesh, Artwork...   \n",
       "1                  dlvr.it  AstraZeneca dispels Indonesian Muslim concerns...   \n",
       "2      Twitter for Android  @prabha_j @MehHarshil @derekobrienmp I think u...   \n",
       "3      Twitter for Android  India seals Myanmar border amid strains over r...   \n",
       "4       Twitter for iPhone  Fleeing coup, Myanmar police refugees in India...   \n",
       "...                    ...                                                ...   \n",
       "22961  Twitter for Android  they went wedding ceremony of they're uncle th...   \n",
       "22962       BPbreakingnews  A labour group yesterday called on the governm...   \n",
       "22963  Twitter for Android  Declare a fly zone right now please. There are...   \n",
       "22964   Twitter for iPhone  @lvandenassum MYANMAR MILITARY REGIME IS CHEAT...   \n",
       "22965      Twitter Web App  The #fire in the #Rohingya refugee #camp leave...   \n",
       "\n",
       "      lang                   id                 created_at  \\\n",
       "0       en  1373792416126402560  2021-03-22 00:23:30+00:00   \n",
       "1       en  1373800977778700288  2021-03-22 00:57:31+00:00   \n",
       "2       en  1373802051524730880  2021-03-22 01:01:47+00:00   \n",
       "3       en  1373802536579174401  2021-03-22 01:03:43+00:00   \n",
       "4       en  1373804367757807619  2021-03-22 01:10:59+00:00   \n",
       "...    ...                  ...                        ...   \n",
       "22961   en  1388268996110266374  2021-04-30 23:08:16+00:00   \n",
       "22962   en  1388272686372057088  2021-04-30 23:22:55+00:00   \n",
       "22963   en  1388273220579741701  2021-04-30 23:25:03+00:00   \n",
       "22964   en  1388273570539782151  2021-04-30 23:26:26+00:00   \n",
       "22965   en  1388274549968437250  2021-04-30 23:30:20+00:00   \n",
       "\n",
       "                 author_id  retweet_count  reply_count  like_count  \\\n",
       "0                 77844813              2            1           2   \n",
       "1               1898083759              1            0           0   \n",
       "2      1209116380257112064              0            0           1   \n",
       "3      1032998054297780224              0            0           0   \n",
       "4                 15552861              1            0           1   \n",
       "...                    ...            ...          ...         ...   \n",
       "22961  1360258667292033028              0            1           6   \n",
       "22962             20583561              3            0           5   \n",
       "22963  1360335395939115010              0            0           0   \n",
       "22964   973730357051838465              0            0           0   \n",
       "22965   733878114011381760              2            0           1   \n",
       "\n",
       "       quote_count  ...  migrant immigrant asylum_seeker  other  \\\n",
       "0                0  ...    False     False         False  False   \n",
       "1                0  ...    False     False         False  False   \n",
       "2                0  ...     True     False         False  False   \n",
       "3                0  ...    False     False         False  False   \n",
       "4                0  ...    False     False         False  False   \n",
       "...            ...  ...      ...       ...           ...    ...   \n",
       "22961            0  ...    False     False         False  False   \n",
       "22962            0  ...    False     False         False  False   \n",
       "22963            0  ...    False     False         False  False   \n",
       "22964            0  ...    False     False         False  False   \n",
       "22965            0  ...    False     False         False  False   \n",
       "\n",
       "                                           text_coherent  retweet_count_sum  \\\n",
       "0      For rohingya Survivors in Bangladesh, Artwork ...                  2   \n",
       "1      AstraZeneca dispels Indonesian Muslim concerns...                  1   \n",
       "2      I think u are one of the illegally migrant Roh...                  0   \n",
       "3      India seals Myanmar border amid strains over r...                  0   \n",
       "4      Fleeing coup, Myanmar police refugees in India...                  1   \n",
       "...                                                  ...                ...   \n",
       "22961  they went wedding ceremony of they' re uncle t...                  0   \n",
       "22962  A labour group yesterday called on the governm...                  3   \n",
       "22963  Declare a fly zone right now please . There ar...                  0   \n",
       "22964  MYANMAR MILITARY REGIME IS CHEATING, MANIPULAT...                  0   \n",
       "22965  The fire in the rohingya refugee camp leaves 4...                  2   \n",
       "\n",
       "       count                                      text_alphanum  \\\n",
       "0          1  for rohingya survivors in bangladesh artwork b...   \n",
       "1          1  astrazeneca dispels indonesian muslim concerns...   \n",
       "2          1  prabhaj mehharshil derekobrienmp i think u are...   \n",
       "3          1  india seals myanmar border amid strains over r...   \n",
       "4          1  fleeing coup myanmar police refugees in india ...   \n",
       "...      ...                                                ...   \n",
       "22961      1  they went wedding ceremony of theyre uncle the...   \n",
       "22962      1  a labour group yesterday called on the governm...   \n",
       "22963      1  declare a fly zone right now please. there are...   \n",
       "22964      1  lvandenassum myanmar military regime is cheati...   \n",
       "22965      1  the fire in the rohingya refugee camp leaves 4...   \n",
       "\n",
       "                                                text_stm is_dup  \n",
       "0      rohingya survivor bangladesh artwork bear witn...  False  \n",
       "1      astrazeneca dispels indonesian muslim concern ...  False  \n",
       "2      think illegally rohingya bangladesh better kee...  False  \n",
       "3           india seal myanmar border amid strain crisis  False  \n",
       "4      fleeing coup myanmar police india seek asylum ...  False  \n",
       "...                                                  ...    ...  \n",
       "22961  went wedding ceremony uncle enjoyed bamboo bri...  False  \n",
       "22962  labour group yesterday called government speed...  False  \n",
       "22963  declare zone right please million karen kachim...  False  \n",
       "22964  myanmar military regime cheating manipulating ...  False  \n",
       "22965  fire rohingya camp leaf people without shelter...  False  \n",
       "\n",
       "[20017 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fuzzy duplicate removal (removes 100% duplicates before more expensive operations - should be done before) \n",
    "#done on dataframe level, we want to keep the ID column to match later on\n",
    "\n",
    "# the comparison will be done on lowercased texts consisting of only letters, digits and spaces\n",
    "#event_df['text_clean'] = event_df['text_clean'].progress_apply(lambda tweet:re.sub(r'[^A-Za-z0-9.!? ]+', '', tweet.lower()))\n",
    "unique_tweets_df = preprocessing.fuzzy_duplicate_removal(event_df)\n",
    "unique_tweets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train this model only after the first merging step to save both memory and time\n",
    "event_cands = load_pickle('rohingya_cands')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training embeddings took 6703.449328184128 seconds\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from sentence_transformers import SentenceTransformer\n",
    "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "bert_corpus = list(unique_tweets_df['text_alphanum']) + list(event_cands['cand_text'])\n",
    "\n",
    "print(bert_corpus[-20:])\n",
    "t0 = time()\n",
    "document_embeddings = sbert_model.encode(bert_corpus)\n",
    "print(f'Training embeddings took {time()-t0} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70464, 768)\n",
      "(20017,)\n",
      "(50447,)\n"
     ]
    }
   ],
   "source": [
    "print(document_embeddings.shape)\n",
    "print(unique_tweets_df['text_alphanum'].shape)\n",
    "print(event_cands['cand_text'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the fire in the rohingya refugee camp leaves 45 000 people without shelter and hundreds missing. httpst.cohpjilanthr'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_corpus[20016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    " \n",
    "sims = cosine_similarity(\n",
    "    [document_embeddings[1002]],\n",
    "    document_embeddings[1003:]\n",
    ")\n",
    "\n",
    "sim_df = pd.DataFrame({'text': bert_corpus[1003:],'sim': list(sims[0])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rows_list = []\n",
    "for up_cand_id in tqdm(range(len(bert_corpus[1000:]))):\n",
    "    for low_cand_id in range(up_cand_id+1,len(bert_corpus[1000:])):\n",
    "        sim = cosine_similarity(\n",
    "            document_embeddings[up_cand_id].reshape(1,-1),\n",
    "            document_embeddings[low_cand_id].reshape(1,-1)\n",
    "        )\n",
    "        dict1 = {}\n",
    "        # get input row in dictionary format\n",
    "        # key = col_name\n",
    "        dict1.update({'text': bert_corpus[up_cand_id], 'text_to_compare':bert_corpus[low_cand_id], 'sim':[sim[0]]}) \n",
    "\n",
    "        rows_list.append(dict1)\n",
    "\n",
    "sim_df = pd.DataFrame(rows_list)\n",
    "sim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file('moria_sim_df',sim_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most similar to \"i keep thinking about the refugees in greece who are receiving so much violence for fleeing certain death  to all these children and families who are lost in an extremely violent world  what will happen tonight and tomorrow without food and shelter\":\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>fires</td>\n",
       "      <td>0.981077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>flames</td>\n",
       "      <td>0.953122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>this fire</td>\n",
       "      <td>0.948744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>fire guts</td>\n",
       "      <td>0.942461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>blaze</td>\n",
       "      <td>0.941246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>a fire</td>\n",
       "      <td>0.939005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>moria fire</td>\n",
       "      <td>0.908484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>the fires</td>\n",
       "      <td>0.907713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the fire</td>\n",
       "      <td>0.907002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>the flames</td>\n",
       "      <td>0.902333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>the blaze</td>\n",
       "      <td>0.894754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>the moria fire</td>\n",
       "      <td>0.879606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>lesbos fire</td>\n",
       "      <td>0.837940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>a massive fire</td>\n",
       "      <td>0.828681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>a devastating fire</td>\n",
       "      <td>0.820698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>the fire in moria</td>\n",
       "      <td>0.819840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>fire at covid</td>\n",
       "      <td>0.815536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>fire departments</td>\n",
       "      <td>0.789699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>firefighters</td>\n",
       "      <td>0.786297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>fire on lesbos</td>\n",
       "      <td>0.774673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>huge fire</td>\n",
       "      <td>0.769656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>arson</td>\n",
       "      <td>0.768699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>the devastating fire</td>\n",
       "      <td>0.767865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>a huge fire</td>\n",
       "      <td>0.767153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>gas</td>\n",
       "      <td>0.764626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>a deadly tent fire</td>\n",
       "      <td>0.763162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>camp fire</td>\n",
       "      <td>0.755081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>catastrophe</td>\n",
       "      <td>0.753824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>police fire</td>\n",
       "      <td>0.726609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>fire on the island</td>\n",
       "      <td>0.721465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>night fire</td>\n",
       "      <td>0.720262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>night fire burning happen</td>\n",
       "      <td>0.719774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>tear gas</td>\n",
       "      <td>0.714120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>fuel</td>\n",
       "      <td>0.710758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>shit</td>\n",
       "      <td>0.707548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>hell</td>\n",
       "      <td>0.707207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>cathedral fire</td>\n",
       "      <td>0.702620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>the moria catastrophe</td>\n",
       "      <td>0.695591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>attack</td>\n",
       "      <td>0.694596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>force</td>\n",
       "      <td>0.692645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>the fuel</td>\n",
       "      <td>0.692418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>fire in greece</td>\n",
       "      <td>0.690953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>matter</td>\n",
       "      <td>0.689430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>camp fire forces</td>\n",
       "      <td>0.684428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>greek camp fire sparks</td>\n",
       "      <td>0.684238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>trauma</td>\n",
       "      <td>0.678141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>an apartment fire</td>\n",
       "      <td>0.676624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>a house fire</td>\n",
       "      <td>0.672023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>pandemic</td>\n",
       "      <td>0.665090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>moria tragedy</td>\n",
       "      <td>0.655075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          text       sim\n",
       "35                       fires  0.981077\n",
       "456                     flames  0.953122\n",
       "382                  this fire  0.948744\n",
       "352                  fire guts  0.942461\n",
       "470                      blaze  0.941246\n",
       "13                      a fire  0.939005\n",
       "132                 moria fire  0.908484\n",
       "159                  the fires  0.907713\n",
       "9                     the fire  0.907002\n",
       "811                 the flames  0.902333\n",
       "341                  the blaze  0.894754\n",
       "669             the moria fire  0.879606\n",
       "441                lesbos fire  0.837940\n",
       "991             a massive fire  0.828681\n",
       "562         a devastating fire  0.820698\n",
       "108          the fire in moria  0.819840\n",
       "929              fire at covid  0.815536\n",
       "178           fire departments  0.789699\n",
       "466               firefighters  0.786297\n",
       "748             fire on lesbos  0.774673\n",
       "516                  huge fire  0.769656\n",
       "239                      arson  0.768699\n",
       "542       the devastating fire  0.767865\n",
       "593                a huge fire  0.767153\n",
       "457                        gas  0.764626\n",
       "773         a deadly tent fire  0.763162\n",
       "685                  camp fire  0.755081\n",
       "314                catastrophe  0.753824\n",
       "580                police fire  0.726609\n",
       "866         fire on the island  0.721465\n",
       "422                 night fire  0.720262\n",
       "238  night fire burning happen  0.719774\n",
       "262                   tear gas  0.714120\n",
       "977                       fuel  0.710758\n",
       "686                       shit  0.707548\n",
       "363                       hell  0.707207\n",
       "607             cathedral fire  0.702620\n",
       "675      the moria catastrophe  0.695591\n",
       "993                     attack  0.694596\n",
       "590                      force  0.692645\n",
       "782                   the fuel  0.692418\n",
       "480             fire in greece  0.690953\n",
       "966                     matter  0.689430\n",
       "406           camp fire forces  0.684428\n",
       "706     greek camp fire sparks  0.684238\n",
       "950                     trauma  0.678141\n",
       "584          an apartment fire  0.676624\n",
       "233               a house fire  0.672023\n",
       "507                   pandemic  0.665090\n",
       "627              moria tragedy  0.655075"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'most similar to \"{bert_corpus[1001]}\":')\n",
    "\n",
    "sim_df.columns = sim_df.columns.str.strip()\n",
    "\n",
    "sim_df.sort_values('sim', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train our own event-specific Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases,ENGLISH_CONNECTOR_WORDS\n",
    "\n",
    "tweet_corpus_tokens = [tweet.split() for tweet in unique_tweets_df['text_coherent']]\n",
    "#tweet_corpus_tokens\n",
    "bigram = Phrases(tweet_corpus_tokens, min_count=10, threshold=10,connector_words=ENGLISH_CONNECTOR_WORDS) # higher threshold, fewer phrases.\n",
    "trigram = Phrases(bigram[tweet_corpus_tokens],min_count=10, threshold=10,connector_words=ENGLISH_CONNECTOR_WORDS) \n",
    "\n",
    "\n",
    "trigram.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: use this if training of ngram models is complete, it only serves purpose of saving memory\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['thank_you', 'for', 'your', 'statement', 'now', 'what', 'action', 'is', 'being', 'taken', 'to', 'get', 'aid', 'to', 'all', 'refugees', 'and', 'civilians', 'in', 'tigray', 'unhcr_the_un', 'refugee_agency', 'united_nations', 'michelle', 'bachelet', 'antnio_guterres', 'united', 'nationshumanrights', 'un_ocha', 'ethiopia', 'filippo_grandi'], ['but', 'antnio_guterres', 'said', 'there', 'are', 'no', 'eritrean_troops', 'in', 'ethiopia', 'he', 'needs', 'to', 'retract', 'his', 'statement', 'withdraw', 'his', 'bid', 'for', 'second', 'term', 'tigray_genocide'], ['we', 'call', 'for', 'global', 'solidarity', 'to', 'stop', 'killings_abductions', 'starvation', 'of', 'civilians', 'and', 'refugees', 'by', 'ethiopian', 'and', 'eritrean_army', 'lord', 'tariqahmad', 'of', 'wimbledon', 'marisepayne', 'mona', 'juul', 'brbel', 'kofler', 'mdb', 'annika', 'ben', 'david', 'minnaliina', 'lind', 'marc', 'garneau'], ['un', 'refugees', 'chief', 'trippin', 'the', 'eritrean_refugees', 'who_were', 'living', 'at', 'shimelba_hitsats', 'have_been', 'attacked', 'by', 'tplf_militants', 'the', 'refugees', 'run_away', 'and', 'found', 'shelter', 'in', 'gonder', 'here', 'is', 'their', 'voices', 'and', 'they', 'said', 'they', 'don_t', 'want', 'go_back', 'to', 'tigrai'], ['out', 'of', '9million', 'tigray_ans', 'over', '45_million', 'people', 'face', 'famine', 'the', 'government', 'is', 'killing', 'unarmed', 'civilians', 'in', 'their_own', 'homes', 'and', 'places', 'of', 'birth', 'destroying', 'everything', 'in', 'their', 'path', 'eritrean_soldiers', 'are', 'rapeing', 'women_children', 'destroying', 'our', 'heritage_sites', 'churches_mosques'], ['tigray', 'is', 'fighting', 'to', 'keep', 'democracy', 'alive', 'as', 'abiy_ahmed', 'is', 'a', 'dictator', 'destroying', 'any', 'progress', 'hes', 'thrown', 'out', 'the', 'constitution', 'laws', 'protected', 'by', 'it', 'he', 'doesnt', 'follow', 'international_laws', 'lost', 'all', 'control', 'do_you', 'prefer', 'the', 'horn', 'to', 'become', 'a', 'home', 'for', 'terrorists', 'b_c', 'were', 'there'], ['ethiopia', 'safe_access', 'and', 'swift_action', 'needed', 'for', 'refugees', 'in', 'tigray', 'the', 'conflict', 'between', 'the', 'ethiopian'], ['yeah', 'the', 'fucking', 'world', 'is', 'descendants', 'of', 'immigrants', 'we', 'should', 'all', 'go_back', 'to', 'ethiopia'], ['when_will', 'this', 'talking', 'ends', 'and', 'action', 'begins', 'fact', 'words', 'are', 'not', 'saving', 'lives', 'in', 'tigray', 'tigray_genocide', 'is_happening', 'at', 'your', 'watch', 'act', 'before', 'its', 'too_late'], ['un_refugee', 'chief', 'very_worried', 'for', 'eritreans', 'in', 'ethiopia']]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "model_phrases = [trigram_mod[tweet] for tweet in tweet_corpus_tokens]\n",
    "print(model_phrases[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINDING BEST PARAMETERS FOR WORD2VEC MODEL\n",
    "\n",
    "#negatives = [5,10,20]\n",
    "sizes = [100,200,300]\n",
    "sgs=[0,1]\n",
    "windows =[3,5] \n",
    "#cbow_means = [0,1]\n",
    "#iters=[10]\n",
    "\n",
    "for size in sizes:\n",
    "        for window in windows:\n",
    "            #print(f'\\nfor params size={size},negative={neg},sg={sg},hs={hs},window={window},cbow_mean={cbow},iter={it}')\n",
    "            print(f'\\nfor params size={size},window={window}')\n",
    "            model = Word2Vec(model_phrases,vector_size=size,window=window)\n",
    "            print(model.wv.most_similar('refugees'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first model done\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# with parameters selected based on the previous cell\n",
    "model = Word2Vec(model_phrases,vector_size=300,window=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('eritrean_refugees', 0.7808598875999451),\n",
       " ('migrants', 0.7493160367012024),\n",
       " ('60000_refugees', 0.7415494322776794),\n",
       " ('have_fled', 0.717192530632019),\n",
       " ('20000_refugees', 0.7117390036582947),\n",
       " ('residents', 0.7110738754272461),\n",
       " ('border', 0.7052704691886902),\n",
       " ('eritrean_refugee', 0.7011108994483948),\n",
       " ('refugee', 0.6936578750610352),\n",
       " ('their_homes', 0.6899452209472656)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('refugees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('immigrants', 0.7028154730796814),\n",
       " ('asylum_seekers', 0.6707106232643127),\n",
       " ('illegal_migrants', 0.6094726324081421),\n",
       " ('illegal_immigrants', 0.6072850227355957),\n",
       " ('migrants', 0.6011469960212708),\n",
       " ('people', 0.595695972442627),\n",
       " ('syrians', 0.5859284400939941),\n",
       " ('economic_migrants', 0.579109251499176),\n",
       " ('these_people', 0.5709031224250793),\n",
       " ('illegals', 0.5647295713424683)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('refugees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file('tigray_w2v_model',model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "for params size=100, window=3 \n",
      "[('refugee_kid', 0.9725989699363708), ('refugee_law', 0.9665269255638123), ('refugee_exodus', 0.9585047364234924), ('refugee_flows', 0.954691469669342), ('refuge', 0.9496657252311707), ('refugee_status', 0.9360215067863464), ('refugee_child', 0.9352647662162781), ('refugee_policy', 0.9234868884086609), ('refugee_committee', 0.9191840291023254), ('kid_refugee', 0.9133069515228271)]\n",
      "\n",
      "for params size=100, window=5 \n",
      "[('refugee_kid', 0.9771548509597778), ('refugee_law', 0.9689993262290955), ('refugee_exodus', 0.960526704788208), ('refugee_flows', 0.9551403522491455), ('refuge', 0.9466025829315186), ('refugee_child', 0.9407798647880554), ('refugee_status', 0.9329602718353271), ('refugee_policy', 0.9241395592689514), ('refugee_committee', 0.9201054573059082), ('took_refuge', 0.909279465675354)]\n",
      "\n",
      "for params size=200, window=3 \n",
      "[('refugee_kid', 0.9748549461364746), ('refugee_law', 0.9703011512756348), ('refugee_exodus', 0.9645267724990845), ('refugee_flows', 0.9556060433387756), ('refuge', 0.9503612518310547), ('refugee_child', 0.9400733113288879), ('refugee_status', 0.9376668930053711), ('refugee_committee', 0.9315598607063293), ('refugee_policy', 0.9302139282226562), ('kid_refugee', 0.9137229323387146)]\n",
      "\n",
      "for params size=200, window=5 \n",
      "[('refugee_kid', 0.9768521785736084), ('refugee_law', 0.9700917601585388), ('refugee_exodus', 0.9631538391113281), ('refugee_flows', 0.9564229846000671), ('refuge', 0.946463406085968), ('refugee_child', 0.9406585693359375), ('refugee_status', 0.9357743859291077), ('refugee_committee', 0.9300172924995422), ('refugee_policy', 0.923314094543457), ('pregnant_refugee', 0.9102300405502319)]\n",
      "\n",
      "for params size=300, window=3 \n",
      "[('refugee_kid', 0.968790590763092), ('refugee_law', 0.9657623767852783), ('refugee_exodus', 0.9577863812446594), ('refuge', 0.9523689150810242), ('refugee_flows', 0.9502414464950562), ('refugee_status', 0.933814287185669), ('refugee_child', 0.9275327324867249), ('refugee_policy', 0.9241487979888916), ('refugee_committee', 0.9176177978515625), ('kid_refugee', 0.914644181728363)]\n",
      "\n",
      "for params size=300, window=5 \n",
      "[('refugee_kid', 0.9775657653808594), ('refugee_law', 0.9704881906509399), ('refugee_exodus', 0.9638486504554749), ('refugee_flows', 0.9572654962539673), ('refuge', 0.9489648342132568), ('refugee_status', 0.9457432627677917), ('refugee_child', 0.9352207183837891), ('refugee_committee', 0.9225418567657471), ('refugee_policy', 0.9216865301132202), ('took_refuge', 0.9132393598556519)]\n"
     ]
    }
   ],
   "source": [
    "# FINDING BEST PARAMETERS FOR FASTTEXT MODEL\n",
    "from gensim.models import FastText\n",
    "\n",
    "sizes = [100,200,300]\n",
    "#losses=['ns','hs','softmax']\n",
    "windows =[3,5] \n",
    "\n",
    "\n",
    "for size in sizes:\n",
    "        for window in windows:\n",
    "            #for loss in losses:\n",
    "                #print(f'\\nfor params size={size},negative={neg},sg={sg},hs={hs},window={window},cbow_mean={cbow},iter={it}')\n",
    "                print(f'\\nfor params size={size}, window={window} ')\n",
    "                model = FastText(model_phrases,vector_size=size,window=window, epochs=10)\n",
    "                print(model.wv.most_similar('refugee'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "model2 = FastText(vector_size=300, window=3, sentences=model_phrases, min_n=4,max_n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('refuge', 0.9909552931785583),\n",
       " ('refuges', 0.9901469349861145),\n",
       " ('refugee_status', 0.9680262207984924),\n",
       " ('danish_refugee', 0.9666343927383423),\n",
       " ('refugee_said', 0.9661538600921631),\n",
       " ('refugees', 0.9506486058235168),\n",
       " ('un_refugee', 0.9475336670875549),\n",
       " ('iraqi_refugees', 0.9409911632537842),\n",
       " ('norwegian_refugee', 0.9401996731758118),\n",
       " ('refugee_camp', 0.9324396252632141)]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.wv.most_similar('refugee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('refugeees', 0.9461631178855896),\n",
       " ('refugee_girl', 0.9091788530349731),\n",
       " ('jesuit_refugee', 0.9081748723983765),\n",
       " ('imperilled_refugee', 0.8926677703857422),\n",
       " ('renewed_refugee', 0.8882556557655334),\n",
       " ('refugee_forum', 0.8876516222953796),\n",
       " ('refugee_scandal', 0.886340320110321),\n",
       " ('refugee_pact', 0.8844466209411621),\n",
       " ('refugee_boy', 0.8822042346000671),\n",
       " ('anti_refugee', 0.8774494528770447)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.wv.most_similar('refugee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6189612"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.wv.similarity('refugee','migrant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file('tigray_ft_model', model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd() + \"/../../../\" + fr\"Dropbox (CBS)/Master thesis data/Candidate Data/greece/greece_ft_model.bin\"\n",
    "model2.save(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.25162622,  0.58416   ,  0.34161314, ..., -0.9051944 ,\n",
       "         0.07126287, -0.21723138],\n",
       "       [-0.28473833,  0.5902117 ,  0.8460189 , ..., -0.33095843,\n",
       "        -0.47118548,  0.47009197],\n",
       "       [-0.28960198,  1.0041703 ,  0.23169023, ..., -0.64314526,\n",
       "        -0.23541632,  0.28106663],\n",
       "       ...,\n",
       "       [-0.03950938, -0.24995442,  1.3851532 , ..., -0.31755453,\n",
       "         0.48770684, -0.23471756],\n",
       "       [ 0.06689067, -0.868989  ,  1.4205451 , ..., -0.2091172 ,\n",
       "         0.09321782, -0.24408102],\n",
       "       [ 0.11261851,  0.28545126,  1.4639302 , ...,  0.28329983,\n",
       "        -0.5337196 , -1.0075337 ]], dtype=float32)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
