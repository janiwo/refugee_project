---
title: "STM"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Import relevant libraries and load the data

```{r }
library(dplyr)
library(tidyr)
library(stringr)
library(tidytext)
library(stm)
library(ggplot2)

file_path = "/Users/Janiwo/Desktop/Clean"
#file_path = "C:/Users/jawo19ad/Dropbox (CBS)/Master thesis data/Event Dataframes/Clean"
greece_path = paste(file_path,"/df_greece_clean.csv", sep = "")
tigray_path = paste(file_path,"/df_tigray_clean.csv", sep = "")
rohingya_path = paste(file_path,"/df_rohingya_clean.csv", sep = "")

# --------------------------------------------------------
# ------------------- Load greece data -------------------
# --------------------------------------------------------
df_greece_raw <- read.csv(file = greece_path,
                          stringsAsFactors = FALSE)

df_greece_raw <- df_greece_raw %>%
  mutate(entity = case_when(
    refugee == "True" & migrant == "False" ~ "Refugee",
    refugee == "True" & migrant == "True" ~ "Both",
    refugee == "False" & migrant == "True" ~ "Migrant",
    refugee == "False" & migrant == "False" ~ "None",
  ))

df_greece_raw$day <- cumsum(!duplicated(df_greece_raw$date))

df_greece <- df_greece_raw %>% select(text_stm, text_coherent, day, entity)



# --------------------------------------------------------
# ------------------- Load tigray data -------------------
# --------------------------------------------------------
df_tigray_raw <- read.csv(file = tigray_path,
                          stringsAsFactors = FALSE)

df_tigray_raw <- df_tigray_raw %>%
  mutate(entity = case_when(
    refugee == "True" & migrant == "False" ~ "Refugee",
    refugee == "True" & migrant == "True" ~ "Both",
    refugee == "False" & migrant == "True" ~ "Migrant",
    refugee == "False" & migrant == "False" ~ "None",
  ))

df_tigray_raw$day <- cumsum(!duplicated(df_tigray_raw$date))

df_tigray <- df_tigray_raw %>% select(text_stm, text_coherent, day, entity)



# --------------------------------------------------------
# ------------------- Load rohingya data -------------------
# --------------------------------------------------------
df_rohingya_raw <- read.csv(file = rohingya_path,
                          stringsAsFactors = FALSE)

df_rohingya_raw <- df_rohingya_raw %>%
  mutate(entity = case_when(
    refugee == "True" & migrant == "False" ~ "Refugee",
    refugee == "True" & migrant == "True" ~ "Both",
    refugee == "False" & migrant == "True" ~ "Migrant",
    refugee == "False" & migrant == "False" ~ "None",
  ))

df_rohingya_raw$day <- cumsum(!duplicated(df_rohingya_raw$date))

df_rohingya <- df_rohingya_raw %>% select(text_stm, text_coherent, day, entity)

```

# Process Text (most already done in Python) and prepare the documents

```{r}
# Process Text
stop_uninformative <- strsplit("according across agreement already also always another anyone around asylum back become breaking came cant case caught cause centre close come condition continue continues could created crisis day deal done dont east enough even every everyone facing first including instead give going good happening head held high huge keep know largest last least left like long longer look made make many maybe mean medium member middle month move much must near need never news next north nothing part people place please problem push reach read really remains report said say saying seeker seen send sending sent series several show side since situation south stand still sure take taken taking talk tell thats thing think time today told took towards true trying turn urgent urgently used using video vice want week well west without whats world would year yesterday"," ")[[1]]

stop_ne <- strsplit("abiy afghan afghanistan africa ahmed amhara andrew ankara antony asean asia assad aung balukhali bangladesh bangladeshi biden blinken borrell bulgaria burma burmese china corona coronavirus covid cox erdogan eritrea eritrean ethiopia ethiopian euro european evros filippo fontelles france freya_cole geneva german germany grandi guterres harris hindu hitsats idlib india indian iran iraq isaias isi italy jammu josep junta justin kachin karen kayin kamala lindat_g lebanon lesbos lesvos libya manipur merkel mizoram moria muslim mutraw myanmar nation nations nato pakistan president putin rohingya rohingyas russia russian secretary shimelba state sudan sudanese tigrai tigrayan tigrayans thai thailand tplf trudeau trump turk unhcr unicef union united unsc"," ")[[1]]

stop_cust <- c(stop_uninformative,stop_ne)


# --------------------------------------------------------
# ------------------- Process greece data ----------------
# --------------------------------------------------------
?textProcessor
processed_greece = textProcessor(df_greece$text_stm, metadata = df_greece,
                                 lowercase = FALSE,
                                 removestopwords = FALSE,
                                 removenumbers = FALSE,
                                 removepunctuation = FALSE,
                                 ucp = FALSE,
                                 stem = FALSE,
                                 customstopwords = stop_cust)

# Prepare Docs
?plotRemoved
rows <- nrow(df_greece)
plotRemoved(processed_greece$documents,
            lower.thresh = seq(as.integer(0.001*rows),
                               as.integer(0.05*rows)))

?prepDocuments
out_greece <- prepDocuments(processed_greece$documents,
                            processed_greece$vocab,
                            processed_greece$meta,
                            lower.thresh = 1000,
                            upper.thresh = 0.5*rows)


# --------------------------------------------------------
# ------------------- Process tigray data ----------------
# --------------------------------------------------------
?textProcessor
processed_tigray = textProcessor(df_tigray$text_stm, metadata = df_tigray,
                                 lowercase = FALSE,
                                 removestopwords = FALSE,
                                 removenumbers = FALSE,
                                 removepunctuation = FALSE,
                                 ucp = FALSE,
                                 stem = FALSE,
                                 customstopwords = stop_cust)

# Prepare Docs
?plotRemoved
rows <- nrow(df_tigray)
plotRemoved(processed_tigray$documents,
            lower.thresh = seq(as.integer(0.001*rows),
                               as.integer(0.05*rows)))

?prepDocuments
out_tigray <- prepDocuments(processed_tigray$documents,
                            processed_tigray$vocab,
                            processed_tigray$meta,
                            lower.thresh = 200,
                            upper.thresh = 0.5*rows)


# --------------------------------------------------------
# ------------------- Process rohingya data --------------
# --------------------------------------------------------
?textProcessor
processed_rohingya = textProcessor(df_rohingya$text_stm, metadata = df_rohingya,
                                  lowercase = FALSE,
                                  removestopwords = FALSE,
                                  removenumbers = FALSE,
                                  removepunctuation = FALSE,
                                  ucp = FALSE,
                                  stem = FALSE,
                                  customstopwords = stop_cust)

# Prepare Docs
?plotRemoved
rows <- nrow(df_rohingya)
plotRemoved(processed_rohingya$documents,
            lower.thresh = seq(as.integer(0.001*rows),
                               as.integer(0.05*rows)))

?prepDocuments
out_rohingya <- prepDocuments(processed_rohingya$documents,
                              processed_rohingya$vocab,
                              processed_rohingya$meta,
                              lower.thresh = 200,
                              upper.thresh = 0.5*rows)
```

# Find optimal number of topics
```{r}

# --------------------------------------------------------
# ------------------- Find k for greece ------------------
# --------------------------------------------------------

# Find best K (use this code to train stm for different K's)
?searchK
# ngroups argument to speed up computation (at the cost of increased memory)
storage_greece <- searchK(documents = out_greece$documents,
                          vocab = out_greece$vocab,
                          K = c(4,5,6,7,8,9,10,11,12),
                          prevalence =~ entity + s(day),
                          data = out_greece$meta,
                          max.em.its = 25,
                          seed = 42)
plot(storage_greece) # -> 7/8 seems to be good
#exclusivity(model_fit, M = 10)


# --------------------------------------------------------
# ------------------- Find k for tigray ------------------
# --------------------------------------------------------

storage_tigray <- searchK(documents = out_tigray$documents,
                          vocab = out_tigray$vocab,
                          K = c(4,5,6,7,8,9,10,11,12),
                          prevalence =~ entity + s(day),
                          data = out_tigray$meta,
                          max.em.its = 25,
                          seed = 42)
plot(storage_tigray)


# --------------------------------------------------------
# ------------------- Find k for rohingya ----------------
# --------------------------------------------------------

storage_rohingya <- searchK(documents = out_rohingya$documents,
                            vocab = out_rohingya$vocab,
                            K = c(4,5,6,7,8,9,10,11,12),
                            prevalence =~ entity + s(day),
                            data = out_rohingya$meta,
                            max.em.its = 25,
                            seed = 42)
plot(storage_rohingya)


# exclusivity -> 
# semantic coherence -> co-occurance of words that are most probabale under a topic in the same document (should be high)
# held-out likelihood -> hold out fraction of words in set of documents, train the model and use the document-level latent variables to evaulate propability of heldout portion (eval.heldout, should be high)
# resilduals -> should be around 1, if it's above, topic number is probabaly too low


#https://www.r-bloggers.com/2018/09/training-evaluating-and-interpreting-topic-models/
# storage_greece$results %>%
#   select(K, exclusivity, semantic_coherence) %>%
#   filter(K %in% c(4,6,8)) %>%
#   unnest() %>%
#   mutate(K = as.factor(K)) %>%
#   ggplot(aes(semantic_coherence, exclusivity, color = K)) +
#   geom_point(size = 2, alpha = 0.7) +
#   labs(x = "Semantic coherence",
#        y = "Exclusivity",
#        title = "Comparing exclusivity and semantic coherence",
#        subtitle = "Models with fewer topics have higher semantic coherence for more topics, but lower exclusivity")



```

# --------------------------------------------------------
# ------------------- GREECE -----------------------------
# --------------------------------------------------------

# Model Creation
```{r}
# --------------------------------------------------------
# ------------------- Build model for greece -------------
# --------------------------------------------------------
# Build candidate models
?stm

model_greece_5 <- stm(documents = out_greece$documents,
                      vocab = out_greece$vocab,
                      K = 5,
                      prevalence =~ entity + s(day),
                      data = out_greece$meta,
                      init.type = "Spectral",
                      seed = 42)

model_greece_6 <- stm(documents = out_greece$documents,
                      vocab = out_greece$vocab,
                      K = 6,
                      prevalence =~ entity + s(day),
                      data = out_greece$meta,
                      init.type = "Spectral",
                      seed = 42)

model_greece_7 <- stm(documents = out_greece$documents,
                      vocab = out_greece$vocab,
                      K = 7,
                      prevalence =~ entity + s(day),
                      data = out_greece$meta,
                      init.type = "Spectral",
                      seed = 42)

model_greece_8 <- stm(documents = out_greece$documents,
                      vocab = out_greece$vocab,
                      K = 8,
                      prevalence =~ entity + s(day),
                      data = out_greece$meta,
                      init.type = "Spectral",
                      seed = 42)

# model_greece <- stm(documents = out_greece$documents,
#                     vocab = out_greece$vocab,
#                     K = 7,
#                     prevalence =~ entity + s(day),
#                     content =~ entity,
#                     data = out_greece$meta,
#                     init.type = "Spectral",
#                     seed = 42)


# Choose the model to investiate

model_greece <- model_greece_6

# Plot the convergence
plot(model_greece$convergence$bound,
     type = "l",
     ylab = "Approximate Convergence",
     main = "Convergence")


# prep2_greece <- estimateEffect(c(7) ~ entity * s(day), model_greece, metadata = out_greece$meta, uncertainty = "None")
# plot(prep2_greece, covariate = "day", model = model_greece, method = "continuous", xlab = "Days", moderator = "entity", moderator.value = "Refugee", linecol = "red", ylim = c(0,0.25), printlegend = FALSE)
# plot(prep2_greece, covariate = "day", model = model_greece, method = "continuous", xlab = "Days", moderator = "entity", moderator.value = "Migrant", linecol = "blue",add = TRUE, printlegend = FALSE)
# legend(0,0.2, c("Refugee","Migrant"), lwd = 2, col = c("red","blue"))
```

# Model Exploration
```{r}
# Label Topics
?labelTopics
labelTopics(model = model_greece,
            n = 10)

# Plot frequency of topics
plot(model_greece, type="summary")

# Plot topic correlations
mod.out.corr <-topicCorr(model_greece)
plot(mod.out.corr)

?toLDAvis
toLDAvis(model_greece, docs = out_greece$documents)

# # Plot the model
# ?plot.STM
# plot.STM(x = model_greece,
#          type = "labels",
#          n = 10)

# # Find thougths
# ?findThoughts # shows documents that are highly associated with a topic
# findThoughts(model = model_greece,
#              texts = out_greece$meta$text_coherent)


# # Plot expected distribution of topic proportions
# plot(model_greece, type="hist")
# 
# # Plot wordcloud of a topic
# cloud(model_greece, topic = 1)
# 
# plot(prep_greece, "date", method="continuous", topics = 5, model = model_greece)



```



# Effect of Covariates
```{r}
## Estimating metadata/topic relationship
?estimateEffect

out_greece$meta$entity <- as.factor(out_greece$meta$entity)
prep_greece <- estimateEffect(1:6 ~ entity + s(day), model_greece, meta = out_greece$meta, uncertainty = "None") # consider using "Global" instead of "None"
summary(prep_greece)
plot(prep_greece, covariate = "entity", topics = c(1,2,3,4,5,6),
     model = model_greece, method = "difference",
     cov.value1 = "Refugee", cov.value2 = "Migrant",
     xlab = "Refugee ... Migrant",
     main = "Effect of tweets containing refugee vs migrants",
     xlim = c(-0.1, 0.1),
     labeltype = "custom",
     custom.labels = c("Topic1","Topic2","Topic3","Topic4","Topic5","Topic6"))

# Compare content covariates
plot(model_greece, type = "perspectives", topics = 7, covarlevels = c("Refugee","Migrant"))

# Compare Frames
plot(model_greece, type = "perspectives", topics = c(1,6))

# Plot topics over time
plot(prep_greece, "day", method = "continuous", topics = c(1,2,3,4,5,6,7), model = model_greece,
     printlegend = FALSE, xaxt ="n", xlab = "Calendar Week")
weekseq <- seq(from = as.Date("2020-02-11"),
               to = as.Date("2020-03-23"),
               by = "week")
weeknames <- strftime(weekseq, format = "%V")
axis(1,at = as.numeric(weekseq) - min(as.numeric(weekseq)), labels = weeknames)
```


# --------------------------------------------------------
# ------------------- TIGRAY -----------------------------
# --------------------------------------------------------

# Model Creation
```{r}
# --------------------------------------------------------
# ------------------- Build model for greece -------------
# --------------------------------------------------------
# Build candidate models
?stm
model_tigray_6 <- stm(documents = out_tigray$documents,
                      vocab = out_tigray$vocab,
                      K = 6,
                      prevalence =~ entity + s(day),
                      data = out_tigray$meta,
                      init.type = "Spectral",
                      seed = 42)

model_tigray_7 <- stm(documents = out_tigray$documents,
                      vocab = out_tigray$vocab,
                      K = 7,
                      prevalence =~ entity + s(day),
                      data = out_tigray$meta,
                      init.type = "Spectral",
                      seed = 42)

model_tigray_8 <- stm(documents = out_tigray$documents,
                      vocab = out_tigray$vocab,
                      K = 8,
                      prevalence =~ entity + s(day),
                      data = out_tigray$meta,
                      init.type = "Spectral",
                      seed = 42)


# Choose the model to investiate

model_tigray <- model_tigray_8

# Plot the convergence
plot(model_tigray$convergence$bound,
     type = "l",
     ylab = "Approximate Convergence",
     main = "Convergence")


# prep2_greece <- estimateEffect(c(7) ~ entity * s(day), model_greece, metadata = out_greece$meta, uncertainty = "None")
# plot(prep2_greece, covariate = "day", model = model_greece, method = "continuous", xlab = "Days", moderator = "entity", moderator.value = "Refugee", linecol = "red", ylim = c(0,0.25), printlegend = FALSE)
# plot(prep2_greece, covariate = "day", model = model_greece, method = "continuous", xlab = "Days", moderator = "entity", moderator.value = "Migrant", linecol = "blue",add = TRUE, printlegend = FALSE)
# legend(0,0.2, c("Refugee","Migrant"), lwd = 2, col = c("red","blue"))
```

# Model Exploration
```{r}
# Label Topics
?labelTopics
labelTopics(model = model_tigray,
            n = 10)

# Plot frequency of topics
plot(model_tigray, type="summary")

# Plot topic correlations
mod.out.corr <-topicCorr(model_tigray)
plot(mod.out.corr)

?toLDAvis
toLDAvis(model_tigray, docs = out_tigray$documents)

# # Plot the model
# ?plot.STM
# plot.STM(x = model_greece,
#          type = "labels",
#          n = 10)

# # Find thougths
# ?findThoughts # shows documents that are highly associated with a topic
# findThoughts(model = model_greece,
#              texts = out_greece$meta$text_coherent)


# # Plot expected distribution of topic proportions
# plot(model_greece, type="hist")
# 
# # Plot wordcloud of a topic
# cloud(model_greece, topic = 1)
# 
# plot(prep_greece, "date", method="continuous", topics = 5, model = model_greece)



```



# Effect of Covariates
```{r}
## Estimating metadata/topic relationship
?estimateEffect

out_tigray$meta$entity <- as.factor(out_tigray$meta$entity)
prep_tigray <- estimateEffect(1:6 ~ entity + s(day), model_tigray, meta = out_tigray$meta, uncertainty = "None") # consider using "Global" instead of "None"
summary(prep_tigray)
plot(prep_tigray, covariate = "entity", topics = c(1,2,3,4,5,6),
     model = model_tigray, method = "difference",
     cov.value1 = "Refugee", cov.value2 = "Migrant",
     xlab = "Refugee ... Migrant",
     main = "Effect of tweets containing refugee vs migrants",
     xlim = c(-0.1, 0.1),
     labeltype = "custom",
     custom.labels = c("Topic1","Topic2","Topic3","Topic4","Topic5","Topic6"))

# Compare content covariates
plot(model_tigray, type = "perspectives", topics = 7, covarlevels = c("Refugee","Migrant"))

# Compare Frames
plot(model_tigray, type = "perspectives", topics = c(1,6))

# Plot topics over time
plot(prep_tigray, "day", method = "continuous", topics = c(1,2,3,4,5,6,7), model = model_tigray,
     printlegend = FALSE, xaxt ="n", xlab = "Calendar Week")
weekseq <- seq(from = as.Date("2020-02-11"),
               to = as.Date("2020-03-23"),
               by = "week")
weeknames <- strftime(weekseq, format = "%V")
axis(1,at = as.numeric(weekseq) - min(as.numeric(weekseq)), labels = weeknames)
```


# --------------------------------------------------------
# ------------------- Rohingya ---------------------------
# --------------------------------------------------------

# Model Creation
```{r}
# --------------------------------------------------------
# ------------------- Build model for greece -------------
# --------------------------------------------------------
# Build candidate models
?stm
model_rohingya_6 <- stm(documents = out_rohingya$documents,
                      vocab = out_rohingya$vocab,
                      K = 6,
                      prevalence =~ entity + s(day),
                      data = out_rohingya$meta,
                      init.type = "Spectral",
                      seed = 42)

model_rohingya_8 <- stm(documents = out_rohingya$documents,
                      vocab = out_rohingya$vocab,
                      K = 8,
                      prevalence =~ entity + s(day),
                      data = out_rohingya$meta,
                      init.type = "Spectral",
                      seed = 42)

model_rohingya_9 <- stm(documents = out_rohingya$documents,
                      vocab = out_rohingya$vocab,
                      K = 9,
                      prevalence =~ entity + s(day),
                      data = out_rohingya$meta,
                      init.type = "Spectral",
                      seed = 42)


# Choose the model to investiate

model_rohingya <- model_rohingya_6

# Plot the convergence
plot(model_rohingya$convergence$bound,
     type = "l",
     ylab = "Approximate Convergence",
     main = "Convergence")


# prep2_greece <- estimateEffect(c(7) ~ entity * s(day), model_greece, metadata = out_greece$meta, uncertainty = "None")
# plot(prep2_greece, covariate = "day", model = model_greece, method = "continuous", xlab = "Days", moderator = "entity", moderator.value = "Refugee", linecol = "red", ylim = c(0,0.25), printlegend = FALSE)
# plot(prep2_greece, covariate = "day", model = model_greece, method = "continuous", xlab = "Days", moderator = "entity", moderator.value = "Migrant", linecol = "blue",add = TRUE, printlegend = FALSE)
# legend(0,0.2, c("Refugee","Migrant"), lwd = 2, col = c("red","blue"))
```

# Model Exploration
```{r}
# Label Topics
?labelTopics
labelTopics(model = model_rohingya,
            n = 6)

# Plot frequency of topics
plot(model_rohingya, type="summary")

# Plot topic correlations
mod.out.corr <-topicCorr(model_rohingya)
plot(mod.out.corr)

?toLDAvis
toLDAvis(model_rohingya, docs = out_rohingya$documents)

# # Plot the model
# ?plot.STM
# plot.STM(x = model_greece,
#          type = "labels",
#          n = 10)

# # Find thougths
# ?findThoughts # shows documents that are highly associated with a topic
# findThoughts(model = model_greece,
#              texts = out_greece$meta$text_coherent)


# # Plot expected distribution of topic proportions
# plot(model_greece, type="hist")
# 
# # Plot wordcloud of a topic
# cloud(model_greece, topic = 1)
# 
# plot(prep_greece, "date", method="continuous", topics = 5, model = model_greece)



```



# Effect of Covariates
```{r}
## Estimating metadata/topic relationship
?estimateEffect

out_rohingya$meta$entity <- as.factor(out_rohingya$meta$entity)
prep_rohingya <- estimateEffect(1:6 ~ entity + s(day), model_rohingya, meta = out_rohingya$meta, uncertainty = "None") # consider using "Global" instead of "None"
summary(prep_rohingya)
plot(prep_rohingya, covariate = "entity", topics = c(1,2,3,4,5,6),
     model = model_rohingya, method = "difference",
     cov.value1 = "Refugee", cov.value2 = "Migrant",
     xlab = "Refugee ... Migrant",
     main = "Effect of tweets containing refugee vs migrants",
     xlim = c(-0.2, 0.2),
     labeltype = "custom",
     custom.labels = c("Topic1","Topic2","Topic3","Topic4","Topic5","Topic6"))

# Compare content covariates
plot(model_rohingya, type = "perspectives", topics = 7, covarlevels = c("Refugee","Migrant"))

# Compare Frames
plot(model_rohingya, type = "perspectives", topics = c(1,6))

# Plot topics over time
plot(prep_rohingya, "day", method = "continuous", topics = c(1,2,3,4,5,6,7), model = model_rohingya,
     printlegend = FALSE, xaxt ="n", xlab = "Calendar Week")
weekseq <- seq(from = as.Date("2020-02-11"),
               to = as.Date("2020-03-23"),
               by = "week")
weeknames <- strftime(weekseq, format = "%V")
axis(1,at = as.numeric(weekseq) - min(as.numeric(weekseq)), labels = weeknames)
```













