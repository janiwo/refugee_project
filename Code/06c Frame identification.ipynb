{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frame identification\n",
    "\n",
    "2 versions - By factor analysis and by using BERT embeddings and clustering (affinity propagation)\n",
    "https://www.datacamp.com/community/tutorials/introduction-factor-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "print(sentence_transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from time import time\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions pickle_file and load_pickle merely help with storing pickled files in the event folders on drive\n",
    "def pickle_file(file_name, file_to_dump):\n",
    "    directory_path = os.getcwd() + \"/../../../../\"\n",
    "    folder_name = file_name.split('_')[0]\n",
    "    file_path = directory_path +  fr\"Dropbox (CBS)/Master thesis data/Candidate Data/{folder_name}/{file_name}\"\n",
    "    with open(file_path, 'wb') as fp:\n",
    "        pickle.dump(file_to_dump, fp)\n",
    "\n",
    "def load_pickle(file_name):\n",
    "    directory_path = os.getcwd() + \"/../../../../\"\n",
    "    folder_name = file_name.split('_')[0]\n",
    "    file_path = directory_path + fr\"Dropbox (CBS)/Master thesis data/Candidate Data/{folder_name}/{file_name}\"\n",
    "    with open(file_path, \"rb\") as input_file:\n",
    "        return pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_url = os.getcwd() + \"/../../../../\" + r\"/Dropbox (CBS)/Master thesis data/\"\n",
    "event_url = file_url + r\"Event Dataframes/\"\n",
    "event_url_clean = event_url + r\"Clean/\"\n",
    "\n",
    "candidate_url = file_url + r\"Candidate Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "tigray_url_clean = event_url_clean + r\"df_tigray_clean.csv\" # location of clean Tigray dataset\n",
    "greece_url_clean = event_url_clean + r\"df_greece_clean.csv\" # location of clean Greece dataset\n",
    "rohingya_url_clean = event_url_clean + r\"df_rohingya_clean.csv\" # location clean of Rohingya dataset\n",
    "channel_url_clean = event_url_clean +r\"df_channel_clean.csv\" #Location of clean Channel dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "tigray_url_fi = event_url_clean + r\"df_tigray_fi.csv\" # location of Tigray dataset for frame identification\n",
    "greece_url_fi = event_url_clean + r\"df_greece_fi.csv\" # location of Greece dataset for frame identification\n",
    "rohingya_url_fi = event_url_clean + r\"df_rohingya_fi.csv\" # location of Rohingya dataset for frame identification\n",
    "channel_url_fi = event_url_clean +r\"df_channel_fi.csv\" #Location of Channel dataset for frame identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "tigray_candidate_url = candidate_url + r\"tigray/tigray_ents\"\n",
    "greece_candidate_url = candidate_url + r\"greece/greece_ents\"\n",
    "rohingya_candidate_url = candidate_url + r\"rohingya/rohingya_ents\"\n",
    "channel_candidate_url = candidate_url + r\"channel/channel_ents\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(greece_candidate_url,\"rb\") as input_file:\n",
    "    ents = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_list(url):\n",
    "    with open(url,\"rb\") as input_file:\n",
    "        ents = pickle.load(input_file)\n",
    "        ents = ents[ents[\"freq\"]>15]\n",
    "        \n",
    "    return list(ents[\"entity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "tigray_ents = get_entity_list(tigray_candidate_url)\n",
    "greece_ents = get_entity_list(greece_candidate_url)\n",
    "rohingya_ents = get_entity_list(rohingya_candidate_url)\n",
    "channel_ents = get_entity_list(channel_candidate_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "ne_list = set(tigray_ents + greece_ents + rohingya_ents + channel_ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "ne_list1 = str.split(\"seeker abiy addis aegean afewerki afeworki afghan afghanistan africa african america amnesty ahmed american amhara andrew ankara antony arab asean asia assad aung bachelet balukhali bangladesh bangladeshi biden blinken boris borisjohnson borrell brexit brit britain british brussels bulgaria burma burmese calais canada channel china commission commissioner corona coronavirus council covid cox dover dublin edirne england english erdoan erdogan eritrea eritrean ethiopia ethiopian euro europe european evros farage filippo fontelles france french freya_cole garneau geneva german germany grandi greece greek guterres haavisto hamdayet harris hindu hitsats houthi houthis idlib idp india indian iran iraq isaias isayas isi israel italy jammu jazeera jerry johnson josep junta justin kachin kadra karen kayin kamala kent kenya kurd labour linda lindat_g lebanon lesbos lesvos libya london maikadra manipur marc merkel michelle mizoram moria muslim mutraw myanmar nation nations nationshumanrights nato nazi nigel november oromia oromo pakistan patel president priti putin reuters rohingya rohingyas russia russian samri secretary shimelba shire somalia spain state sudan sudanese syria syrian tegaru tigrai tigrayan tigrayans thai thailand tory tplf trudeau trump turk turkey turkish unhcr unicef union united unsc us yemen youtube\",\" \")\n",
    "ne_list2 = str.split(\"able absolutely access according account accountable across action actually affected agency agree agreement alive allegation allow allowed allowing almost alone along already also always ambassador amid among another answer anti anymore anyone anything area arent around arrived article asylum attempt attention away back based basic become believe best better black blame blocked born breaking bring brother build call called calling came cant case caught cause centre change claim claiming clear clearly close come coming comment commited commiting completely concern concerned condemn condition confirmed  continue continues could country course cover created credible crisis currently daily day deal dear decade decision demand department despite didnt difference different dire doesnt done dont east eastern easy either effort else endf enough especially ethnic even ever every everyone everything evidence evil exactly expect extremely face facility facing fact failed fake false federal feel find first found four forget free fuck fucking full genuine getting given giving great ground group happy imagine including issue instead isnt give going good half hand happen happened happening hard head heading held high horn hour however huge idea image immediate immediately independent information inside internal internally interview investigate investigation issue join journalist keep kind know known lack land landing largest last latest leader least left let letting level lie like likely little live living load local long longer look looking lost made mail major majority make making many massive matter maybe mean medium member middle might migration mind month morning mostly move much must name national near nearly need needed neighboring never news next nobody north northern nothing obviously office official one ongoing operation others paid part party pas past people perhaps person place plan please point post press prevails prime probably problem process programme provide public push putting question quite rather reach read real realise reality really reason received recent record remains remember report reported reporting resident response responsible rest result right said satellite say saying second seek seeker seeking seem seems seen send sending sent series service several shame share shit show side simple simply since single site situation small someone something soon sorry sort south source speak special spread stand star start started statement street still stop stopped stopping story stupid sure surely system take taken taking talk talking tell term testimony thank thanks thats there theyre thing think though thought three time today told took torn towards town tried true truth trying turn tweet understand unless urgent urgently used using video vice view virus visit voice wait waiting want wanted watch water week welcome well west western withdraw within without whats whilst white whole wing wish wonder wont word world worse wrong would year yesterday young youre\",\" \")\n",
    "ne_list = ne_list1 + ne_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_event_df(data_url):\n",
    "    # easy dataframe load\n",
    "    event_df = pd.read_csv(data_url, index_col=0)\n",
    "    event_df.reset_index(drop=True, inplace=True)\n",
    "    event_df = event_df[event_df['text_stm'].notna()]\n",
    "    print(f'loaded {event_df.shape[0]} tweets!')\n",
    "    return event_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 42843 tweets!\n",
      "loaded 137418 tweets!\n",
      "loaded 29423 tweets!\n",
      "loaded 173615 tweets!\n"
     ]
    }
   ],
   "source": [
    "df_tigray = read_event_df(tigray_url_clean)\n",
    "df_greece = read_event_df(greece_url_clean)\n",
    "df_rohingya = read_event_df(rohingya_url_clean)\n",
    "df_channel = read_event_df(channel_url_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "all_words = list()\n",
    "\n",
    "for words in df_channel[\"text_stm\"]:\n",
    "    words_tok = word_tokenize(words)\n",
    "    for word in words_tok:\n",
    "        all_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter(all_words)\n",
    "counter.most_common() #counter_obj.most_common(n=10)\n",
    "\n",
    "most_frequent_words = [pair[0] for pair in counter.most_common(int(len(counter)*0.025))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1245"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(most_frequent_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_frequent_words(df_col):\n",
    "    \n",
    "    all_words = list()\n",
    "    \n",
    "    for words in df_col:\n",
    "        for word in words:\n",
    "            all_words.append(word)\n",
    "            \n",
    "    counter = Counter(all_words)\n",
    "    \n",
    "    return [pair[0] for pair in counter.most_common(int(len(counter)*0.025))] #0.025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(df_col):\n",
    "    \"\"\"\n",
    "    Takes a list with strings and returns a list with tokens\n",
    "    \"\"\"\n",
    "    print(\"Tokenizing tweets...\\n\")\n",
    "    return df_col.apply(lambda x: word_tokenize(x))\n",
    "\n",
    "def remove_unfrequent_words(df_col):\n",
    "    print(\"Removing unfrequent words...\\n\")\n",
    "    most_frequent_words = get_most_frequent_words(df_col)\n",
    "    print(f\"(Removing words that are not among {len(most_frequent_words)} most frequent ones.)\\n\")\n",
    "    return df_col.apply(lambda x: [token for token in x if token in most_frequent_words])\n",
    "\n",
    "def remove_named_entities(df_col):\n",
    "    print(\"Removing named entities...\\n\")\n",
    "    return df_col.apply(lambda x: [token for token in x if token not in ne_list])\n",
    "\n",
    "def preprocessing(df_col, *steps):\n",
    "    \"\"\"\n",
    "    Takes in a dataframe column with text and applies preprocessing steps given \n",
    "    in and returns a string.\n",
    "    \n",
    "    Input:\n",
    "    - df (dataframe): The dataframe containing the text column.\n",
    "    - steps (functions): Multiple functions for preprocessing can be given in.\n",
    "    \n",
    "    Output:\n",
    "    - List with strings.\n",
    "    \"\"\"\n",
    "    # copying over the column for preprocessing\n",
    "    temp = df_col.copy()\n",
    "    for func in steps:\n",
    "        temp = func(temp)\n",
    "    return temp.apply(lambda x: \" \".join([token for token in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def remove_words(df_col, min_words):\n",
    "#    \n",
    "#    most_frequent_words = get_most_frequent_words(df_col, min_words)\n",
    "#    print(f\"(Removing words that are not among {len(most_frequent_words)} most frequent ones.)\\n\")\n",
    "#    \n",
    "#    words_to_keep = [word for word in most_frequent_words if word not in ne_list]\n",
    "#    \n",
    "#    df_col =  df_col.apply(lambda x: [token for token in x if token in words_to_keep])\n",
    "#    return df_col.apply(lambda x: \" \".join([token for token in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_greece[\"tok\"] = tokenization(df_greece[\"text_stm\"])\n",
    "\n",
    "#df_greece[\"text_frame_identification_001\"] = remove_words(df_greece[\"tok\"],0.001)\n",
    "#df_greece[\"text_frame_identification_0025\"] = remove_words(df_greece[\"tok\"],0.025)\n",
    "#df_greece[\"text_frame_identification_005\"] = remove_words(df_greece[\"tok\"],0.05)\n",
    "#df_greece[\"text_frame_identification_01\"] = remove_words(df_greece[\"tok\"],0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing tweets...\n",
      "\n",
      "Removing unfrequent words...\n",
      "\n",
      "(Removing words that are not among 1251 most frequent ones.)\n",
      "\n",
      "Removing named entities...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_greece[\"text_frame_identification\"] = preprocessing(df_greece[\"text_stm\"],\n",
    "                                                  tokenization,\n",
    "                                                  remove_unfrequent_words,\n",
    "                                                  remove_named_entities)\n",
    "\n",
    "most_frequent_words = get_most_frequent_words(df_greece[\"text_stm\"].apply(lambda x: word_tokenize(x)))\n",
    "words_to_cluster_greece = [word for word in most_frequent_words if word not in ne_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing tweets...\n",
      "\n",
      "Removing unfrequent words...\n",
      "\n",
      "(Removing words that are not among 649 most frequent ones.)\n",
      "\n",
      "Removing named entities...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_tigray[\"text_frame_identification\"] = preprocessing(df_tigray[\"text_stm\"],\n",
    "                                                  tokenization,\n",
    "                                                  remove_unfrequent_words,\n",
    "                                                  remove_named_entities)\n",
    "\n",
    "most_frequent_words = get_most_frequent_words(df_tigray[\"text_stm\"].apply(lambda x: word_tokenize(x)))\n",
    "words_to_cluster_tigray = [word for word in most_frequent_words if word not in ne_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing tweets...\n",
      "\n",
      "Removing unfrequent words...\n",
      "\n",
      "(Removing words that are not among 1245 most frequent ones.)\n",
      "\n",
      "Removing named entities...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_channel[\"text_frame_identification\"] = preprocessing(df_channel[\"text_stm\"],\n",
    "                                                  tokenization,\n",
    "                                                  remove_unfrequent_words,\n",
    "                                                  remove_named_entities)\n",
    "\n",
    "most_frequent_words = get_most_frequent_words(df_channel[\"text_stm\"].apply(lambda x: word_tokenize(x)))\n",
    "words_to_cluster_channel = [word for word in most_frequent_words if word not in ne_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing tweets...\n",
      "\n",
      "Removing unfrequent words...\n",
      "\n",
      "(Removing words that are not among 486 most frequent ones.)\n",
      "\n",
      "Removing named entities...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_rohingya[\"text_frame_identification\"] = preprocessing(df_rohingya[\"text_stm\"],\n",
    "                                                  tokenization,\n",
    "                                                  remove_unfrequent_words,\n",
    "                                                  remove_named_entities)\n",
    "\n",
    "most_frequent_words = get_most_frequent_words(df_rohingya[\"text_stm\"].apply(lambda x: word_tokenize(x)))\n",
    "words_to_cluster_rohingya = [word for word in most_frequent_words if word not in ne_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['source', 'text', 'lang', 'id', 'created_at', 'author_id',\n",
       "       'retweet_count', 'reply_count', 'like_count', 'quote_count',\n",
       "       'withheld.scope', 'hashtags', 'mentions', 'annotations', 'text_clean',\n",
       "       'year', 'calendar_week', 'year_month', 'year_calendar_week', 'refugee',\n",
       "       'migrant', 'immigrant', 'asylum_seeker', 'other', 'date',\n",
       "       'text_coherent', 'retweet_count_sum', 'count', 'text_alphanum',\n",
       "       'text_stm', 'text_frame_identification', 'tok',\n",
       "       'text_frame_identification_0025', 'text_frame_identification_001',\n",
       "       'text_frame_identification_005', 'text_frame_identification_01'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_greece.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_greece_test = df_greece[[\"text\",\"text_coherent\",\"text_frame_identification\",\"date\",'text_frame_identification_0025', 'text_frame_identification_001',\n",
    "       'text_frame_identification_005', 'text_frame_identification_01']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_greece_test.to_csv('C:\\\\Users\\\\jawo19ad\\\\Documents\\\\GitHub\\\\refugee_project\\\\Code/../../../..//Dropbox (CBS)/Master thesis data/Event Dataframes/Clean/df_greece_fi_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_greece_frame = df_greece[[\"text\",\"text_coherent\",\"text_frame_identification\",\"date\"]]\n",
    "df_tigray_frame = df_tigray[[\"text\",\"text_coherent\",\"text_frame_identification\",\"date\"]]\n",
    "df_rohingya_frame = df_rohingya[[\"text\",\"text_coherent\",\"text_frame_identification\",\"date\"]]\n",
    "df_channel_frame = df_channel[[\"text\",\"text_coherent\",\"text_frame_identification\",\"date\"]]\n",
    "\n",
    "#df_greece_frame.to_csv(greece_url_fi)\n",
    "#df_tigray_frame.to_csv(tigray_url_fi)\n",
    "#df_rohingya_frame.to_csv(rohingya_url_fi)\n",
    "#df_channel_frame.to_csv(channel_url_fi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_greece[\"text_frame_identification_len\"] = df_greece[\"text_frame_identification\"].apply(lambda x: len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     20356\n",
       "1     19806\n",
       "4     19368\n",
       "2     19349\n",
       "5     16773\n",
       "6     13681\n",
       "7     10174\n",
       "8      7295\n",
       "9      4707\n",
       "10     2857\n",
       "11     1624\n",
       "12      807\n",
       "13      387\n",
       "14      138\n",
       "15       62\n",
       "16       17\n",
       "17       12\n",
       "18        3\n",
       "19        1\n",
       "20        1\n",
       "Name: text_frame_identification_len, dtype: int64"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_greece[\"text_frame_identification_len\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98263, 32)"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_greece_frame = df_greece[df_greece[\"text_frame_identification_len\"] > 2]\n",
    "df_greece_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "from factor_analyzer import FactorAnalyzer\n",
    "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity\n",
    "from factor_analyzer.factor_analyzer import calculate_kmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = vectorizer.fit_transform(df_greece_frame[\"text_frame_identification\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dense = embeddings.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\factor_analyzer\\utils.py:248: UserWarning: The inverse of the variance-covariance matrix was calculated using the Moore-Penrose generalized matrix inversion, due to its determinant being at or very close to zero.\n",
      "  warnings.warn('The inverse of the variance-covariance matrix '\n"
     ]
    }
   ],
   "source": [
    "kmo_all,kmo_model=calculate_kmo(embeddings_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "778"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kmo_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(kmo_all > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True, False,  True, False, False, False, False,\n",
       "       False,  True,  True,  True, False, False, False, False, False,\n",
       "        True,  True, False, False, False,  True,  True,  True, False,\n",
       "        True,  True,  True, False,  True, False,  True, False, False,\n",
       "       False,  True,  True, False, False,  True, False,  True,  True,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "        True, False, False,  True,  True,  True, False, False, False,\n",
       "        True,  True, False,  True, False, False, False, False,  True,\n",
       "        True, False, False, False, False, False, False,  True,  True,\n",
       "       False, False,  True,  True,  True, False,  True,  True, False,\n",
       "        True, False, False, False, False, False, False, False,  True,\n",
       "        True,  True, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False,  True, False, False, False,  True,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False,  True,\n",
       "       False,  True,  True, False, False, False,  True, False, False,\n",
       "       False,  True, False, False,  True,  True, False,  True,  True,\n",
       "        True,  True,  True, False,  True, False, False, False, False,\n",
       "       False, False,  True, False,  True,  True,  True, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False,  True])"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_keep = [feature for feature,b in zip(features, tf) if b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_greece = [word for word in vectorizer.get_feature_names() if word not in words_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "?TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer1 = TfidfVectorizer(stop_words=stopwords_greece,smooth_idf=True)\n",
    "embeddings1 = vectorizer1.fit_transform(df_greece_frame[\"text_frame_identification\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ally',\n",
       " 'army',\n",
       " 'attacking',\n",
       " 'boat',\n",
       " 'bomb',\n",
       " 'bombing',\n",
       " 'center',\n",
       " 'child',\n",
       " 'civil',\n",
       " 'civilian',\n",
       " 'clash',\n",
       " 'coast',\n",
       " 'coastguard',\n",
       " 'community',\n",
       " 'control',\n",
       " 'create',\n",
       " 'cross',\n",
       " 'crossing',\n",
       " 'defend',\n",
       " 'dictator',\n",
       " 'displaced',\n",
       " 'family',\n",
       " 'fence',\n",
       " 'fire',\n",
       " 'fled',\n",
       " 'flee',\n",
       " 'food',\n",
       " 'force',\n",
       " 'foreign',\n",
       " 'guard',\n",
       " 'health',\n",
       " 'host',\n",
       " 'hosting',\n",
       " 'humanitarian',\n",
       " 'humanity',\n",
       " 'hundred',\n",
       " 'illegally',\n",
       " 'immigration',\n",
       " 'innocent',\n",
       " 'island',\n",
       " 'jihadist',\n",
       " 'kid',\n",
       " 'killed',\n",
       " 'military',\n",
       " 'movement',\n",
       " 'order',\n",
       " 'police',\n",
       " 'prevent',\n",
       " 'protect',\n",
       " 'protection',\n",
       " 'regime',\n",
       " 'return',\n",
       " 'safe',\n",
       " 'safety',\n",
       " 'school',\n",
       " 'security',\n",
       " 'shelter',\n",
       " 'shooting',\n",
       " 'shot',\n",
       " 'soldier',\n",
       " 'tear',\n",
       " 'territory',\n",
       " 'terrorist',\n",
       " 'thousand',\n",
       " 'woman',\n",
       " 'zone']"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer1.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dense1 = embeddings1.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67181.24183884518, 0.0)"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bartlett’s test of sphericity (want to have p-value of 0)\n",
    "chi_square_value, p_value=calculate_bartlett_sphericity(embeddings_dense1)\n",
    "chi_square_value, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\factor_analyzer\\utils.py:248: UserWarning: The inverse of the variance-covariance matrix was calculated using the Moore-Penrose generalized matrix inversion, due to its determinant being at or very close to zero.\n",
      "  warnings.warn('The inverse of the variance-covariance matrix '\n"
     ]
    }
   ],
   "source": [
    "kmo_all,kmo_model=calculate_kmo(embeddings_dense1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4883275042305532"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmo_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kmo_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(kmo_all > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.6133827 , 2.21037773, 2.12808771, 2.04872536, 2.01324092,\n",
       "       1.90343566, 1.89038957, 1.82144031, 1.75288218, 1.74958462,\n",
       "       1.7160321 , 1.70984263, 1.66775106, 1.65539361, 1.63624676,\n",
       "       1.6196999 , 1.584113  , 1.57075678, 1.55080911, 1.52357934,\n",
       "       1.49535572, 1.49120354, 1.48432804, 1.46049544, 1.44536733,\n",
       "       1.43985184, 1.42082628, 1.41223356, 1.40794068, 1.39993617,\n",
       "       1.39127757, 1.38471745, 1.37605247, 1.36986083, 1.36368748,\n",
       "       1.35871824, 1.35384487, 1.35022442, 1.34645162, 1.33980598,\n",
       "       1.33716343, 1.32927996, 1.32224255, 1.3201675 , 1.31703714,\n",
       "       1.30960781, 1.304993  , 1.29997222, 1.29439724, 1.2923078 ,\n",
       "       1.28884352, 1.28360973, 1.28074422, 1.27847388, 1.2750048 ,\n",
       "       1.2683426 , 1.26370021, 1.26196918, 1.25695892, 1.25553796,\n",
       "       1.25358248, 1.2483135 , 1.24606822, 1.24139883, 1.23827763,\n",
       "       1.23678631, 1.23268562, 1.23223136, 1.22958554, 1.22643913,\n",
       "       1.22377065, 1.22296032, 1.22158892, 1.21678385, 1.21584955,\n",
       "       1.21413195, 1.21189851, 1.21050263, 1.20665593, 1.2033628 ,\n",
       "       1.20115484, 1.19924095, 1.19668283, 1.19464511, 1.19442801,\n",
       "       1.19223573, 1.19033711, 1.18854498, 1.18684997, 1.18614371,\n",
       "       1.18499582, 1.18283992, 1.18072052, 1.17966738, 1.17786823,\n",
       "       1.17728226, 1.17442632, 1.17370664, 1.17132072, 1.17013511,\n",
       "       1.16882796, 1.16738785, 1.16702667, 1.16534249, 1.16463422,\n",
       "       1.1620738 , 1.1599853 , 1.1594525 , 1.15829417, 1.15604177,\n",
       "       1.15419999, 1.15260648, 1.15205585, 1.15045578, 1.1498182 ,\n",
       "       1.14852588, 1.14654822, 1.14563244, 1.14384672, 1.14293065,\n",
       "       1.14258213, 1.14165947, 1.14085956, 1.13972801, 1.13909492,\n",
       "       1.13796002, 1.13635623, 1.13554615, 1.13524457, 1.13439059,\n",
       "       1.13273679, 1.13176013, 1.13121889, 1.13047328, 1.12981036,\n",
       "       1.12875078, 1.12730753, 1.12643062, 1.12430435, 1.12343745,\n",
       "       1.1223771 , 1.12204146, 1.1214629 , 1.12064099, 1.11915242,\n",
       "       1.1186818 , 1.11848107, 1.11581332, 1.11549238, 1.11515533,\n",
       "       1.11430079, 1.11315571, 1.11249893, 1.11164029, 1.11085845,\n",
       "       1.11073175, 1.10953854, 1.10843111, 1.10752406, 1.10697648,\n",
       "       1.10609879, 1.10558176, 1.10481134, 1.10360738, 1.10248221,\n",
       "       1.10220893, 1.10083083, 1.10070261, 1.09984978, 1.09872209,\n",
       "       1.09803722, 1.09699803, 1.09650563, 1.09608623, 1.09491307,\n",
       "       1.09471811, 1.09377521, 1.09303753, 1.09255636, 1.09151162,\n",
       "       1.0913966 , 1.0896672 , 1.08901185, 1.08884735, 1.08802722,\n",
       "       1.08777279, 1.08729665, 1.08635564, 1.0859864 , 1.08547415,\n",
       "       1.08438079, 1.08368572, 1.08300032, 1.08224721, 1.08154777,\n",
       "       1.08133349, 1.08049391, 1.07979532, 1.07929228, 1.07846014,\n",
       "       1.07841944, 1.07738876, 1.0772188 , 1.07660259, 1.07617068,\n",
       "       1.07552274, 1.07459123, 1.07397497, 1.07354492, 1.07333966,\n",
       "       1.07252793, 1.07181169, 1.07114885, 1.07035389, 1.06964099,\n",
       "       1.06915827, 1.06832307, 1.0678288 , 1.06699577, 1.06599433,\n",
       "       1.06580692, 1.06537336, 1.06456028, 1.06422989, 1.06405337,\n",
       "       1.06369555, 1.06270627, 1.06246527, 1.06178918, 1.06094822,\n",
       "       1.06005254, 1.05973196, 1.05938776, 1.05885939, 1.05817105,\n",
       "       1.05758458, 1.05706904, 1.05652419, 1.05578477, 1.05526182,\n",
       "       1.05489829, 1.05383948, 1.05341519, 1.05287226, 1.05250894,\n",
       "       1.05233556, 1.05153031, 1.05129492, 1.05046879, 1.05022286,\n",
       "       1.04991489, 1.04932569, 1.04881736, 1.04865368, 1.04804279,\n",
       "       1.04757787, 1.04670939, 1.04648397, 1.04577085, 1.04511985,\n",
       "       1.04446195, 1.04414743, 1.04303612, 1.04204318, 1.04191818,\n",
       "       1.04149185, 1.04109109, 1.04085498, 1.04034224, 1.03971583,\n",
       "       1.03890368, 1.03804426, 1.03774831, 1.03737249, 1.03677498,\n",
       "       1.03670604, 1.03625776, 1.03573504, 1.03478364, 1.03431482,\n",
       "       1.0334622 , 1.03320696, 1.03284911, 1.03197715, 1.03170173,\n",
       "       1.03164761, 1.03068708, 1.03035686, 1.02944997, 1.02891541,\n",
       "       1.02872224, 1.02840056, 1.02788652, 1.02760127, 1.02718934,\n",
       "       1.02597445, 1.02575748, 1.02512411, 1.024492  , 1.02416775,\n",
       "       1.0238984 , 1.023173  , 1.0230744 , 1.02226778, 1.02185951,\n",
       "       1.02167092, 1.0212191 , 1.02050949, 1.01961991, 1.01923973,\n",
       "       1.0189434 , 1.01830505, 1.0181786 , 1.01766007, 1.01751576,\n",
       "       1.0167434 , 1.01638967, 1.01572918, 1.01543454, 1.01485579,\n",
       "       1.01410674, 1.01360147, 1.01308737, 1.01289664, 1.01256834,\n",
       "       1.0120947 , 1.01142809, 1.01124007, 1.01036387, 1.01004511,\n",
       "       1.00972169, 1.00902541, 1.00856498, 1.0079712 , 1.00751099,\n",
       "       1.00716947, 1.00623147, 1.00605206, 1.00571976, 1.004996  ,\n",
       "       1.00463148, 1.00408367, 1.00366332, 1.0034179 , 1.00251349,\n",
       "       1.00242418, 1.00186017, 1.00150351, 1.00139777, 1.00089279,\n",
       "       1.00072138, 1.00059641, 0.99975892, 0.99925576, 0.99862618,\n",
       "       0.99782346, 0.99706242, 0.99685134, 0.9963034 , 0.99589   ,\n",
       "       0.99557829, 0.99521622, 0.99446263, 0.99412245, 0.99356693,\n",
       "       0.99278701, 0.99257591, 0.99232609, 0.99214097, 0.99162657,\n",
       "       0.99080421, 0.990473  , 0.99011772, 0.98975193, 0.98930317,\n",
       "       0.98861568, 0.98827622, 0.98789589, 0.9875479 , 0.98718011,\n",
       "       0.9863512 , 0.98564643, 0.98520093, 0.98513138, 0.9846261 ,\n",
       "       0.98369739, 0.98331441, 0.9829068 , 0.98270271, 0.98221768,\n",
       "       0.98167462, 0.98129686, 0.98072364, 0.98014218, 0.98002602,\n",
       "       0.97921796, 0.97896337, 0.97868938, 0.97830447, 0.97801159,\n",
       "       0.97707448, 0.97642189, 0.97632913, 0.97610188, 0.97600988,\n",
       "       0.97467868, 0.97421295, 0.97384171, 0.97332972, 0.97299259,\n",
       "       0.97233398, 0.97162957, 0.97145187, 0.97135227, 0.97118336,\n",
       "       0.97004265, 0.96970296, 0.96934911, 0.96896309, 0.96877888,\n",
       "       0.96850302, 0.96806381, 0.9673955 , 0.96694727, 0.96587792,\n",
       "       0.96566483, 0.96514904, 0.96506022, 0.96446324, 0.96383443,\n",
       "       0.96365947, 0.96293523, 0.96236551, 0.96193321, 0.96116593,\n",
       "       0.9610068 , 0.96046303, 0.95993147, 0.95976795, 0.95920524,\n",
       "       0.95881208, 0.95828681, 0.95772338, 0.95740517, 0.95718263,\n",
       "       0.95666374, 0.95569891, 0.95548376, 0.95506183, 0.95478446,\n",
       "       0.9545573 , 0.9541546 , 0.95342971, 0.95269993, 0.95214783,\n",
       "       0.95175374, 0.95131863, 0.95080156, 0.95034797, 0.94967745,\n",
       "       0.94945966, 0.94928843, 0.94855775, 0.94834789, 0.94766244,\n",
       "       0.94704874, 0.94690949, 0.94673981, 0.94631846, 0.94579084,\n",
       "       0.94496336, 0.94462028, 0.94411154, 0.94358522, 0.9433777 ,\n",
       "       0.94264719, 0.94222036, 0.94182548, 0.94144019, 0.94089305,\n",
       "       0.94076411, 0.94014078, 0.93983221, 0.93881512, 0.93869771,\n",
       "       0.93803807, 0.93781097, 0.93706091, 0.93681392, 0.93642677,\n",
       "       0.93562216, 0.93528926, 0.93494709, 0.93473111, 0.93342473,\n",
       "       0.93298501, 0.9326835 , 0.93229476, 0.93160211, 0.93083817,\n",
       "       0.9306444 , 0.93035031, 0.92975226, 0.92920194, 0.92899485,\n",
       "       0.9285032 , 0.9279174 , 0.92711062, 0.92662287, 0.92580231,\n",
       "       0.92532386, 0.92494935, 0.92490061, 0.92407447, 0.92385011,\n",
       "       0.92350849, 0.92326406, 0.9223625 , 0.92197293, 0.92151454,\n",
       "       0.92080798, 0.92004497, 0.91991769, 0.91917922, 0.919002  ,\n",
       "       0.91830378, 0.91813439, 0.91787089, 0.91730959, 0.91668495,\n",
       "       0.91622265, 0.9156341 , 0.91487178, 0.91467511, 0.91394992,\n",
       "       0.91366245, 0.91322673, 0.91243775, 0.91229719, 0.91177586,\n",
       "       0.91101409, 0.91044263, 0.90966798, 0.90886652, 0.90850046,\n",
       "       0.90802918, 0.90751132, 0.90742419, 0.90673661, 0.90634111,\n",
       "       0.90557002, 0.90456367, 0.9038759 , 0.9037101 , 0.90341103,\n",
       "       0.90264162, 0.90255712, 0.90159261, 0.90126909, 0.90099851,\n",
       "       0.90034096, 0.89964463, 0.89869052, 0.89823621, 0.89777437,\n",
       "       0.89716806, 0.89694697, 0.89657703, 0.89577664, 0.89563859,\n",
       "       0.89533434, 0.89465664, 0.89388655, 0.8933674 , 0.89289014,\n",
       "       0.89258672, 0.89193069, 0.89035424, 0.89008826, 0.88963396,\n",
       "       0.88952324, 0.88898546, 0.88843301, 0.88821392, 0.88764536,\n",
       "       0.88661332, 0.88613193, 0.88588045, 0.8852744 , 0.88422988,\n",
       "       0.88367392, 0.88328667, 0.88287175, 0.88263713, 0.88188784,\n",
       "       0.88152093, 0.88027079, 0.88008589, 0.87930683, 0.87860905,\n",
       "       0.87806889, 0.8773536 , 0.87664544, 0.87632616, 0.87602116,\n",
       "       0.8754882 , 0.87343029, 0.87300003, 0.87266822, 0.87205986,\n",
       "       0.87122261, 0.87103637, 0.87023412, 0.86944233, 0.86890112,\n",
       "       0.86820137, 0.86777961, 0.86762973, 0.86637237, 0.86580762,\n",
       "       0.86488917, 0.86462929, 0.86414651, 0.86350318, 0.86227963,\n",
       "       0.86198615, 0.86024177, 0.8596215 , 0.85939672, 0.85838036,\n",
       "       0.85783507, 0.85711161, 0.8564064 , 0.855931  , 0.85531862,\n",
       "       0.85446687, 0.8536498 , 0.85255618, 0.85203575, 0.85177573,\n",
       "       0.85081627, 0.85018105, 0.84955311, 0.84917618, 0.84833495,\n",
       "       0.84782275, 0.84722219, 0.8461148 , 0.84493655, 0.84416259,\n",
       "       0.84329062, 0.84294134, 0.84193705, 0.84151232, 0.84118192,\n",
       "       0.83948343, 0.83896834, 0.83851933, 0.83758377, 0.83705664,\n",
       "       0.83559127, 0.83493521, 0.83397636, 0.83348067, 0.83300866,\n",
       "       0.83165676, 0.8313976 , 0.82994539, 0.82968823, 0.82812767,\n",
       "       0.82710668, 0.82657351, 0.82615845, 0.82516884, 0.82441222,\n",
       "       0.82363571, 0.8212585 , 0.82076177, 0.81996036, 0.81826273,\n",
       "       0.81687248, 0.81649707, 0.81501385, 0.814182  , 0.8123753 ,\n",
       "       0.81168405, 0.81102317, 0.80992622, 0.80832197, 0.80717365,\n",
       "       0.8067727 , 0.8046577 , 0.80351705, 0.80216927, 0.80097231,\n",
       "       0.800606  , 0.79890568, 0.79834982, 0.79706931, 0.79548805,\n",
       "       0.79499709, 0.79371202, 0.79285417, 0.79086477, 0.79057787,\n",
       "       0.78861518, 0.78828011, 0.78757423, 0.78550124, 0.7846049 ,\n",
       "       0.78170738, 0.78093196, 0.77919921, 0.77844311, 0.77615888,\n",
       "       0.77574359, 0.7734064 , 0.77231771, 0.76885365, 0.767881  ,\n",
       "       0.76539477, 0.76379732, 0.76069206, 0.75877264, 0.75756696,\n",
       "       0.75716253, 0.75571259, 0.7529901 , 0.75112969, 0.74973951,\n",
       "       0.74699838, 0.74557526, 0.74360548, 0.74033241, 0.73994026,\n",
       "       0.73373908, 0.73242283, 0.73096114, 0.73030286, 0.72965711,\n",
       "       0.72650718, 0.72189281, 0.72034926, 0.71781853, 0.7169429 ,\n",
       "       0.71581986, 0.71272724, 0.71084134, 0.70375315, 0.69570099,\n",
       "       0.69173823, 0.68717798, 0.68541606, 0.68309366, 0.67074151,\n",
       "       0.66698955, 0.66399684, 0.65437167, 0.65139277, 0.64733275,\n",
       "       0.639902  , 0.63553964, 0.62736821, 0.61385991, 0.57809585,\n",
       "       0.56771374, 0.56467725, 0.55035507, 0.54385308, 0.51829518,\n",
       "       0.49352844, 0.4279511 , 0.36146357, 0.31527019, 0.18129493,\n",
       "       0.15894114, 0.13562954, 0.11714997])"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa = FactorAnalyzer(rotation=\"varimax\")\n",
    "fa.fit(embeddings_dense)\n",
    "print(\"Fit finished\")\n",
    "# Check Eigenvalues\n",
    "ev, v = fa.get_eigenvalues()\n",
    "ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create scree plot using matplotlib\n",
    "plt.scatter(range(1,embeddings_dense1.shape[1]+1),ev)\n",
    "plt.plot(range(1,embeddings_dense1.shape[1]+1),ev)\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Factors')\n",
    "plt.ylabel('Eigenvalue')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?fa.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FactorAnalyzer(n_factors=6, rotation='varimax', rotation_kwargs={})"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa = FactorAnalyzer(6, rotation=\"varimax\")\n",
    "fa.fit(embeddings_dense1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.18090070e-02, -2.35786231e-03, -1.13885291e-02,\n",
       "        -7.18883940e-02, -7.45804864e-03,  8.22315045e-03],\n",
       "       [-3.04770220e-02, -1.17877831e-02, -5.63155471e-02,\n",
       "        -3.63028750e-03, -2.25365244e-02,  3.28309722e-02],\n",
       "       [ 2.19867315e-02, -1.60083135e-02, -2.12166517e-02,\n",
       "         9.65154712e-03, -1.09406375e-02,  2.65093410e-02],\n",
       "       [ 3.14493130e-01, -1.31574422e-02,  2.16547877e-02,\n",
       "         7.90007249e-02, -2.24769774e-02, -1.50403080e-03],\n",
       "       [-2.66709063e-02, -1.96561139e-02,  2.25698441e-02,\n",
       "        -2.12021903e-03, -1.77978275e-02,  5.49844908e-02],\n",
       "       [-1.24503740e-02, -6.52222418e-03,  3.66794122e-03,\n",
       "        -1.04045365e-01, -5.94007252e-03,  4.74827825e-02],\n",
       "       [-1.01441525e-02, -1.07609729e-03, -1.26556348e-02,\n",
       "         8.35074611e-02, -2.78719922e-02, -2.52565694e-01],\n",
       "       [-4.44914045e-03, -6.19417741e-02,  5.45025013e-01,\n",
       "         1.67582957e-01, -4.39866733e-02,  1.13214310e-01],\n",
       "       [-8.74556545e-03, -8.48155919e-03,  1.02679493e-02,\n",
       "        -5.58814233e-02, -7.18616226e-03, -1.75461413e-02],\n",
       "       [-1.89480111e-02, -6.96997812e-04,  5.78050108e-03,\n",
       "        -1.62453924e-01,  6.60850797e-03,  9.89049881e-02],\n",
       "       [-6.32432184e-02, -2.68504383e-02, -9.93455584e-02,\n",
       "         1.69145629e-01, -3.32183140e-02,  1.60376705e-02],\n",
       "       [ 7.69322794e-01,  1.07085628e-02, -3.84776856e-02,\n",
       "         1.11680277e-01,  9.91196652e-03,  6.94412951e-02],\n",
       "       [ 5.99096606e-02, -1.57329847e-02,  4.91723476e-03,\n",
       "         2.52705372e-02, -1.55920141e-02, -1.91063236e-02],\n",
       "       [-4.28473683e-03, -9.44287131e-03,  1.73203317e-02,\n",
       "        -2.10854373e-02, -5.77349593e-03, -5.58074457e-02],\n",
       "       [-7.40485206e-04, -1.21259722e-02, -3.04530429e-02,\n",
       "         1.66659395e-03, -1.53740115e-02, -2.13189679e-01],\n",
       "       [-1.70903632e-02, -9.10103924e-03, -1.45248468e-02,\n",
       "        -2.03078997e-02,  1.70397043e-01, -6.35355804e-03],\n",
       "       [-9.36375363e-03,  2.15182117e-02, -8.30779535e-02,\n",
       "         4.61059326e-02, -3.75593633e-02,  4.60529784e-02],\n",
       "       [ 4.15764531e-03,  7.37427073e-03, -4.41183049e-02,\n",
       "         4.22485431e-02, -1.54169159e-02, -1.39331093e-02],\n",
       "       [-4.62440670e-03, -1.06392357e-02, -2.09924553e-02,\n",
       "        -2.48159221e-02, -8.60579134e-03, -9.41147605e-03],\n",
       "       [-8.60037737e-03, -4.91633054e-03, -6.96094746e-03,\n",
       "        -4.10754571e-02, -5.18883911e-03, -7.64330037e-03],\n",
       "       [-2.74712735e-02,  1.37563985e-02,  9.72736704e-02,\n",
       "        -1.40760585e-01, -3.31418660e-02,  5.18527991e-02],\n",
       "       [-1.92487805e-02, -1.55424635e-02,  1.00900020e-01,\n",
       "        -1.48877276e-02, -1.75608888e-02, -2.32437893e-02],\n",
       "       [-2.63483763e-02, -1.59822564e-02, -6.67300625e-02,\n",
       "         6.58469718e-02, -2.08969081e-02,  3.71237486e-02],\n",
       "       [-1.15824605e-02, -4.60440546e-02, -4.41703873e-02,\n",
       "         1.94020737e-01, -4.47834938e-02,  6.25378119e-02],\n",
       "       [-9.84354026e-03,  6.15535452e-03,  5.99573002e-02,\n",
       "        -4.63944841e-02, -4.02849051e-03,  7.62862629e-03],\n",
       "       [-1.25622110e-02,  2.33548675e-02,  1.77169885e-02,\n",
       "        -5.25410198e-02,  3.72874791e-03,  7.23440076e-03],\n",
       "       [-1.26814402e-02, -5.86019558e-03,  7.65481472e-02,\n",
       "        -1.18001065e-02, -1.04284979e-02, -1.58028109e-02],\n",
       "       [-3.15814895e-02, -3.24687136e-02, -1.02063504e-01,\n",
       "         4.55461606e-03, -3.13867818e-02,  5.93808181e-02],\n",
       "       [-9.58244084e-03, -9.25592157e-03, -2.02647912e-02,\n",
       "        -3.34647623e-02, -1.09319117e-02, -5.97199361e-02],\n",
       "       [ 5.60959233e-01, -1.04115741e-03, -8.19450228e-02,\n",
       "         1.08191559e-01, -1.90400883e-02,  1.19904545e-01],\n",
       "       [-9.42750606e-03, -1.08132008e-02,  2.19892273e-02,\n",
       "        -2.33121885e-02, -9.62436732e-03, -5.07844685e-02],\n",
       "       [-1.13396544e-02, -3.50223061e-03,  7.28914287e-03,\n",
       "        -4.38600930e-02,  1.59447813e-02, -2.63951653e-02],\n",
       "       [-9.60563710e-03,  1.32206154e-03, -4.56047044e-03,\n",
       "        -4.26394344e-02,  5.91068090e-03, -1.59239503e-02],\n",
       "       [-1.29935867e-02, -5.90313651e-03,  3.05899919e-02,\n",
       "        -8.32764767e-02, -1.18411371e-02, -1.80287011e-02],\n",
       "       [-1.77763667e-03, -1.56916181e-02,  1.58262024e-02,\n",
       "        -3.12504081e-02, -1.71912589e-02,  9.70309021e-03],\n",
       "       [-2.34247897e-02,  1.47907745e-01, -2.33451232e-02,\n",
       "         5.11492928e-03, -2.11367045e-02,  2.92040899e-02],\n",
       "       [-4.74911520e-03, -1.53273065e-03, -4.05434902e-02,\n",
       "         1.45822824e-03, -1.63855517e-03, -1.61695091e-02],\n",
       "       [-8.48354584e-03, -1.38500418e-02, -1.29058961e-02,\n",
       "        -2.19539702e-02, -1.58057623e-02, -1.03412677e-01],\n",
       "       [-6.05795025e-03, -1.07511587e-02,  1.63376458e-02,\n",
       "        -5.77006102e-02, -1.86616013e-02,  6.36610068e-02],\n",
       "       [ 2.39828554e-02, -5.77558927e-03,  3.03395703e-02,\n",
       "         1.07271825e-01, -1.72367499e-02, -1.43624145e-01],\n",
       "       [-1.14511001e-02, -3.94740888e-03, -1.69596225e-02,\n",
       "        -4.44576433e-02, -2.04534682e-03, -4.79457495e-03],\n",
       "       [-5.27958236e-03, -1.08856040e-02,  5.92827677e-02,\n",
       "         2.30622022e-03, -8.62756605e-03,  7.49969234e-03],\n",
       "       [-1.34010272e-02, -7.15455184e-03, -3.02604346e-02,\n",
       "        -8.41447486e-02, -7.20584886e-02,  1.60410061e-01],\n",
       "       [-1.72169189e-02, -1.27655082e-02, -3.95927447e-02,\n",
       "        -1.54841446e-02, -2.11208341e-02, -7.34517611e-03],\n",
       "       [ 4.18117676e-04, -7.60574363e-03, -1.33251516e-02,\n",
       "         2.10818504e-02, -1.73584947e-02, -2.32062344e-01],\n",
       "       [ 1.81639656e-02, -1.16571369e-02, -3.11591752e-02,\n",
       "        -5.95889621e-03,  6.13634965e-03, -2.34607799e-02],\n",
       "       [-1.24510839e-01, -7.41638751e-02, -2.31009109e-01,\n",
       "         3.80387006e-01, -9.10192035e-02,  1.54195491e-01],\n",
       "       [-4.52447748e-03, -7.77704865e-03, -5.56157874e-02,\n",
       "         7.57573568e-03,  1.99534198e-03, -3.08202553e-02],\n",
       "       [-1.31770020e-02, -1.11082429e-02, -1.68852517e-02,\n",
       "        -6.18435897e-02,  2.61846557e-02,  7.94823467e-03],\n",
       "       [-9.71808114e-03, -8.13006696e-03,  1.89994048e-02,\n",
       "        -2.31951230e-02, -1.58223889e-03, -2.68414744e-02],\n",
       "       [-2.29902089e-02, -2.63562724e-03, -1.71272812e-02,\n",
       "        -1.58634523e-01,  1.69271981e-02,  6.72578935e-02],\n",
       "       [-3.63280954e-03, -1.17968862e-02, -2.72674407e-02,\n",
       "        -2.06208131e-02,  4.24183307e-02, -5.35607679e-02],\n",
       "       [-2.85033309e-02, -1.48959018e-02,  7.34491793e-03,\n",
       "         4.25493402e-04,  4.32757571e-01,  3.25578340e-03],\n",
       "       [-3.36372345e-03, -6.71941588e-03,  2.87728464e-02,\n",
       "        -2.64968940e-02,  1.89102085e-02, -1.43465624e-02],\n",
       "       [-1.11067188e-02, -1.56492639e-02,  7.25543963e-02,\n",
       "        -1.90768215e-02, -1.66805769e-02, -9.13441626e-03],\n",
       "       [-3.22880237e-03, -1.65130388e-02, -5.76441720e-02,\n",
       "        -1.32971383e-02, -1.03644102e-03,  1.82001999e-02],\n",
       "       [-1.27165603e-02,  1.99905264e-03,  6.06439319e-02,\n",
       "        -3.38686081e-02, -2.67351575e-03, -3.41766532e-03],\n",
       "       [ 4.59917892e-02, -1.84526758e-02, -2.75622961e-02,\n",
       "         1.64818052e-02, -2.61157901e-02,  4.49217718e-02],\n",
       "       [ 3.77776099e-02, -1.56051147e-02, -5.23112398e-02,\n",
       "         3.81735172e-02, -3.60805010e-02,  7.93106801e-02],\n",
       "       [-1.73166543e-02, -1.73977605e-02, -5.99973783e-02,\n",
       "        -7.59639679e-02, -4.74074967e-02,  1.10881904e-01],\n",
       "       [-7.12281492e-02, -4.82075033e-02, -1.23712880e-01,\n",
       "         2.66565267e-01, -6.30163460e-02,  1.55130394e-01],\n",
       "       [-6.58846048e-03,  2.50664980e-03, -3.28441649e-02,\n",
       "        -1.34765775e-02,  1.55154532e-02, -5.30409512e-02],\n",
       "       [-2.02056445e-02, -1.39438812e-02, -1.90992466e-02,\n",
       "        -8.78977738e-02,  6.20719174e-03, -4.22232554e-04],\n",
       "       [-6.07687015e-02,  9.91078437e-01,  1.73027598e-02,\n",
       "         9.15641312e-02, -3.01844107e-02,  2.20256283e-02],\n",
       "       [-1.77483417e-02, -3.85438817e-02,  3.52647909e-01,\n",
       "         8.72446599e-02, -2.58372423e-02,  7.20908215e-02],\n",
       "       [-3.85635519e-02, -7.96086749e-03, -2.97740112e-02,\n",
       "        -2.05491987e-03,  5.09421136e-01,  3.79598196e-02]])"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa.loadings_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>million</th>\n",
       "      <th>right</th>\n",
       "      <th>crisis</th>\n",
       "      <th>stop</th>\n",
       "      <th>help</th>\n",
       "      <th>camp</th>\n",
       "      <th>child</th>\n",
       "      <th>year</th>\n",
       "      <th>back</th>\n",
       "      <th>illegal</th>\n",
       "      <th>...</th>\n",
       "      <th>migration</th>\n",
       "      <th>policy</th>\n",
       "      <th>invasion</th>\n",
       "      <th>another</th>\n",
       "      <th>give</th>\n",
       "      <th>last</th>\n",
       "      <th>work</th>\n",
       "      <th>today</th>\n",
       "      <th>fire</th>\n",
       "      <th>free</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.011809</td>\n",
       "      <td>-0.030477</td>\n",
       "      <td>0.021987</td>\n",
       "      <td>0.314493</td>\n",
       "      <td>-0.026671</td>\n",
       "      <td>-0.012450</td>\n",
       "      <td>-0.010144</td>\n",
       "      <td>-0.004449</td>\n",
       "      <td>-0.008746</td>\n",
       "      <td>-0.018948</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012717</td>\n",
       "      <td>0.045992</td>\n",
       "      <td>0.037778</td>\n",
       "      <td>-0.017317</td>\n",
       "      <td>-0.071228</td>\n",
       "      <td>-0.006588</td>\n",
       "      <td>-0.020206</td>\n",
       "      <td>-0.060769</td>\n",
       "      <td>-0.017748</td>\n",
       "      <td>-0.038564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.002358</td>\n",
       "      <td>-0.011788</td>\n",
       "      <td>-0.016008</td>\n",
       "      <td>-0.013157</td>\n",
       "      <td>-0.019656</td>\n",
       "      <td>-0.006522</td>\n",
       "      <td>-0.001076</td>\n",
       "      <td>-0.061942</td>\n",
       "      <td>-0.008482</td>\n",
       "      <td>-0.000697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>-0.018453</td>\n",
       "      <td>-0.015605</td>\n",
       "      <td>-0.017398</td>\n",
       "      <td>-0.048208</td>\n",
       "      <td>0.002507</td>\n",
       "      <td>-0.013944</td>\n",
       "      <td>0.991078</td>\n",
       "      <td>-0.038544</td>\n",
       "      <td>-0.007961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.011389</td>\n",
       "      <td>-0.056316</td>\n",
       "      <td>-0.021217</td>\n",
       "      <td>0.021655</td>\n",
       "      <td>0.022570</td>\n",
       "      <td>0.003668</td>\n",
       "      <td>-0.012656</td>\n",
       "      <td>0.545025</td>\n",
       "      <td>0.010268</td>\n",
       "      <td>0.005781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060644</td>\n",
       "      <td>-0.027562</td>\n",
       "      <td>-0.052311</td>\n",
       "      <td>-0.059997</td>\n",
       "      <td>-0.123713</td>\n",
       "      <td>-0.032844</td>\n",
       "      <td>-0.019099</td>\n",
       "      <td>0.017303</td>\n",
       "      <td>0.352648</td>\n",
       "      <td>-0.029774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.071888</td>\n",
       "      <td>-0.003630</td>\n",
       "      <td>0.009652</td>\n",
       "      <td>0.079001</td>\n",
       "      <td>-0.002120</td>\n",
       "      <td>-0.104045</td>\n",
       "      <td>0.083507</td>\n",
       "      <td>0.167583</td>\n",
       "      <td>-0.055881</td>\n",
       "      <td>-0.162454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033869</td>\n",
       "      <td>0.016482</td>\n",
       "      <td>0.038174</td>\n",
       "      <td>-0.075964</td>\n",
       "      <td>0.266565</td>\n",
       "      <td>-0.013477</td>\n",
       "      <td>-0.087898</td>\n",
       "      <td>0.091564</td>\n",
       "      <td>0.087245</td>\n",
       "      <td>-0.002055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.007458</td>\n",
       "      <td>-0.022537</td>\n",
       "      <td>-0.010941</td>\n",
       "      <td>-0.022477</td>\n",
       "      <td>-0.017798</td>\n",
       "      <td>-0.005940</td>\n",
       "      <td>-0.027872</td>\n",
       "      <td>-0.043987</td>\n",
       "      <td>-0.007186</td>\n",
       "      <td>0.006609</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002674</td>\n",
       "      <td>-0.026116</td>\n",
       "      <td>-0.036081</td>\n",
       "      <td>-0.047407</td>\n",
       "      <td>-0.063016</td>\n",
       "      <td>0.015515</td>\n",
       "      <td>0.006207</td>\n",
       "      <td>-0.030184</td>\n",
       "      <td>-0.025837</td>\n",
       "      <td>0.509421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.008223</td>\n",
       "      <td>0.032831</td>\n",
       "      <td>0.026509</td>\n",
       "      <td>-0.001504</td>\n",
       "      <td>0.054984</td>\n",
       "      <td>0.047483</td>\n",
       "      <td>-0.252566</td>\n",
       "      <td>0.113214</td>\n",
       "      <td>-0.017546</td>\n",
       "      <td>0.098905</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003418</td>\n",
       "      <td>0.044922</td>\n",
       "      <td>0.079311</td>\n",
       "      <td>0.110882</td>\n",
       "      <td>0.155130</td>\n",
       "      <td>-0.053041</td>\n",
       "      <td>-0.000422</td>\n",
       "      <td>0.022026</td>\n",
       "      <td>0.072091</td>\n",
       "      <td>0.037960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    million     right    crisis      stop      help      camp     child  \\\n",
       "0 -0.011809 -0.030477  0.021987  0.314493 -0.026671 -0.012450 -0.010144   \n",
       "1 -0.002358 -0.011788 -0.016008 -0.013157 -0.019656 -0.006522 -0.001076   \n",
       "2 -0.011389 -0.056316 -0.021217  0.021655  0.022570  0.003668 -0.012656   \n",
       "3 -0.071888 -0.003630  0.009652  0.079001 -0.002120 -0.104045  0.083507   \n",
       "4 -0.007458 -0.022537 -0.010941 -0.022477 -0.017798 -0.005940 -0.027872   \n",
       "5  0.008223  0.032831  0.026509 -0.001504  0.054984  0.047483 -0.252566   \n",
       "\n",
       "       year      back   illegal  ...  migration    policy  invasion   another  \\\n",
       "0 -0.004449 -0.008746 -0.018948  ...  -0.012717  0.045992  0.037778 -0.017317   \n",
       "1 -0.061942 -0.008482 -0.000697  ...   0.001999 -0.018453 -0.015605 -0.017398   \n",
       "2  0.545025  0.010268  0.005781  ...   0.060644 -0.027562 -0.052311 -0.059997   \n",
       "3  0.167583 -0.055881 -0.162454  ...  -0.033869  0.016482  0.038174 -0.075964   \n",
       "4 -0.043987 -0.007186  0.006609  ...  -0.002674 -0.026116 -0.036081 -0.047407   \n",
       "5  0.113214 -0.017546  0.098905  ...  -0.003418  0.044922  0.079311  0.110882   \n",
       "\n",
       "       give      last      work     today      fire      free  \n",
       "0 -0.071228 -0.006588 -0.020206 -0.060769 -0.017748 -0.038564  \n",
       "1 -0.048208  0.002507 -0.013944  0.991078 -0.038544 -0.007961  \n",
       "2 -0.123713 -0.032844 -0.019099  0.017303  0.352648 -0.029774  \n",
       "3  0.266565 -0.013477 -0.087898  0.091564  0.087245 -0.002055  \n",
       "4 -0.063016  0.015515  0.006207 -0.030184 -0.025837  0.509421  \n",
       "5  0.155130 -0.053041 -0.000422  0.022026  0.072091  0.037960  \n",
       "\n",
       "[6 rows x 66 columns]"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor_dict =dict()\n",
    "for word,factor in zip(words_to_cluster,fa.loadings_):\n",
    "    factor_dict[word] = factor\n",
    "    \n",
    "factor_df = pd.DataFrame.from_dict(factor_dict)\n",
    "factor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>stop</th>\n",
       "      <td>0.314493</td>\n",
       "      <td>-0.013157</td>\n",
       "      <td>0.021655</td>\n",
       "      <td>0.079001</td>\n",
       "      <td>-0.022477</td>\n",
       "      <td>-0.001504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>human</th>\n",
       "      <td>0.769323</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>-0.038478</td>\n",
       "      <td>0.111680</td>\n",
       "      <td>0.009912</td>\n",
       "      <td>0.069441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>life</th>\n",
       "      <td>0.560959</td>\n",
       "      <td>-0.001041</td>\n",
       "      <td>-0.081945</td>\n",
       "      <td>0.108192</td>\n",
       "      <td>-0.019040</td>\n",
       "      <td>0.119905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5\n",
       "stop   0.314493 -0.013157  0.021655  0.079001 -0.022477 -0.001504\n",
       "human  0.769323  0.010709 -0.038478  0.111680  0.009912  0.069441\n",
       "life   0.560959 -0.001041 -0.081945  0.108192 -0.019040  0.119905"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor_df_transposed = factor_df.T \n",
    "factor_df_transposed[factor_df_transposed[0]>0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62252, 66)"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_dict =dict()\n",
    "for word,vector in zip(words_to_cluster,embeddings):\n",
    "    vector_dict[word] = vector\n",
    "    \n",
    "vector_df = pd.DataFrame.from_dict(vector_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                               life\n",
       "1                                             border\n",
       "2                                               wave\n",
       "3                                     island hosting\n",
       "4                                                   \n",
       "                             ...                    \n",
       "137457                                              \n",
       "137458                     army border mass invasion\n",
       "137459                                poor home work\n",
       "137460           attack border invasion attack force\n",
       "137461    crime attack fighting invader border guard\n",
       "Name: text_frame_identification, Length: 137418, dtype: object"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_greece[\"text_frame_identification\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bert_embedding(df, words_to_cluster):\n",
    "    \n",
    "    tweet_sentences = [sent for tweet in df['text_alphanum'] for sent in sent_tokenize(tweet)]\n",
    "    sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "    bert_corpus = tweet_sentences + words_to_cluster\n",
    "\n",
    "    print(len(bert_corpus))\n",
    "    t0 = time()\n",
    "    document_embeddings = sbert_model.encode(bert_corpus)\n",
    "    print(f'Training embeddings took {time()-t0} seconds')\n",
    "    \n",
    "    return document_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357611\n",
      "Training embeddings took 17201.172611951828 seconds\n"
     ]
    }
   ],
   "source": [
    "greece_bert = create_bert_embedding(df_greece, words_to_cluster_greece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108610\n",
      "Training embeddings took 6313.1803567409515 seconds\n"
     ]
    }
   ],
   "source": [
    "tigray_bert = create_bert_embedding(df_tigray, words_to_cluster_tigray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68993\n",
      "Training embeddings took 3697.816387653351 seconds\n"
     ]
    }
   ],
   "source": [
    "rohingya_bert = create_bert_embedding(df_rohingya, words_to_cluster_rohingya)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484502\n",
      "Training embeddings took 23848.87373805046 seconds\n"
     ]
    }
   ],
   "source": [
    "channel_bert = create_bert_embedding(df_channel, words_to_cluster_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file('greece_frame_embeddings', greece_bert)\n",
    "pickle_file('tigray_frame_embeddings', tigray_bert)\n",
    "pickle_file('rohingya_frame_embeddings', rohingya_bert)\n",
    "pickle_file('channel_frame_embeddings', channel_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file('greece_words_to_cluster', words_to_cluster_greece)\n",
    "pickle_file('tigray_words_to_cluster', words_to_cluster_tigray)\n",
    "pickle_file('rohingya_words_to_cluster', words_to_cluster_rohingya)\n",
    "pickle_file('channel_words_to_cluster', words_to_cluster_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "bert_corpus = tweet_sentences + words_to_cluster\n",
    "\n",
    "print(len(bert_corpus))\n",
    "t0 = time()\n",
    "document_embeddings = sbert_model.encode(bert_corpus)\n",
    "print(f'Training embeddings took {time()-t0} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentence_transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'document_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-9f704284ad9a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwords_embeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdocument_embeddings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet_sentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords_embeddings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'document_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "words_embeddings = document_embeddings[len(tweet_sentences):]\n",
    "len(words_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(zip(vectorizer.get_feature_names(), embeddings.toarray()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_sentences_greece = [sent for tweet in df_greece['text_alphanum'] for sent in sent_tokenize(tweet)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings_greece = greece_bert[len(tweet_sentences_greece):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "stopwords = [word for word in vectorizer.get_feature_names() if word not in words_to_cluster]\n",
    "vectorizer = TfidfVectorizer(stop_words = stopwords)\n",
    "\n",
    "embeddings = vectorizer.fit_transform(unique_tweets_df['text_alphanum'])\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "tweet_sentences = [sent for tweet in unique_tweets_df['text_alphanum'] for sent in sent_tokenize(tweet)]\n",
    "len(tweet_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sentence_transformers import SentenceTransformer\n",
    "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "bert_corpus = tweet_sentences + words_to_cluster\n",
    "\n",
    "print(len(bert_corpus))\n",
    "t0 = time()\n",
    "document_embeddings = sbert_model.encode(bert_corpus)\n",
    "print(f'Training embeddings took {time()-t0} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_embeddings = document_embeddings[len(tweet_sentences):]\n",
    "len(words_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(zip(vectorizer.get_feature_names(), embeddings.toarray()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_embeddings = load_pickle('greece_bert_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_embeddings = word_embeddings_greece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_dict =dict()\n",
    "for word,vector in zip(words_to_cluster_greece,words_embeddings):\n",
    "    vector_dict[word] = vector\n",
    "    \n",
    "vector_df = pd.DataFrame.from_dict(vector_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\factor_analyzer\\factor_analyzer.py:118: RuntimeWarning: divide by zero encountered in log\n",
      "  statistic = -np.log(corr_det) * (n - 1 - (2 * p + 5) / 6)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_continuous_distns.py:1266: RuntimeWarning: invalid value encountered in subtract\n",
      "  return sc.xlogy(df/2.-1, x) - x/2. - sc.gammaln(df/2.) - (np.log(2)*df)/2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(inf, nan)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_square_value, p_value=calculate_bartlett_sphericity(vector_df)\n",
    "chi_square_value, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from factor_analyzer.factor_analyzer import calculate_kmo\n",
    "kmo_all,kmo_model=calculate_kmo(vector_df)\n",
    "kmo_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, ..., nan, nan, nan])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmo_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.98170822e+02,  6.15643496e+01,  2.74392388e+01, ...,\n",
       "       -6.80665489e-15, -7.23782721e-15, -1.31274389e-14])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from factor_analyzer import FactorAnalyzer\n",
    "# Create factor analysis object and perform factor analysis\n",
    "fa = FactorAnalyzer()\n",
    "fa.fit(vector_df)\n",
    "eigen_values, vectors = fa.get_eigenvalues()\n",
    "ev, v = fa.get_eigenvalues()\n",
    "ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5591498 ,  0.26232961,  0.1421388 , ...,  0.52135674,\n",
       "         0.1564291 , -0.08579294],\n",
       "       [ 0.80202759,  0.2402963 ,  0.42277575, ...,  0.10855167,\n",
       "         0.14933181,  0.00148477],\n",
       "       [ 0.45446674,  0.75851588,  0.1387505 , ...,  0.17084086,\n",
       "         0.00321452,  0.17205969],\n",
       "       ...,\n",
       "       [ 0.26801312,  0.4440313 ,  0.03012718, ...,  0.13391058,\n",
       "         0.17683644, -0.04121899],\n",
       "       [ 0.65853832,  0.3494775 ,  0.23577034, ...,  0.09016037,\n",
       "         0.05169822, -0.01761102],\n",
       "       [-0.01549855,  0.60395185,  0.2936716 , ...,  0.23852288,\n",
       "        -0.16654519,  0.03617725]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa = FactorAnalyzer(8,rotation='varimax')\n",
    "fa.fit(vector_df)\n",
    "fa.loadings_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>million</th>\n",
       "      <th>right</th>\n",
       "      <th>crisis</th>\n",
       "      <th>stop</th>\n",
       "      <th>help</th>\n",
       "      <th>camp</th>\n",
       "      <th>child</th>\n",
       "      <th>year</th>\n",
       "      <th>back</th>\n",
       "      <th>illegal</th>\n",
       "      <th>...</th>\n",
       "      <th>funded</th>\n",
       "      <th>leverage</th>\n",
       "      <th>vehicle</th>\n",
       "      <th>weaponized</th>\n",
       "      <th>nine</th>\n",
       "      <th>naked</th>\n",
       "      <th>secure</th>\n",
       "      <th>alien</th>\n",
       "      <th>vessel</th>\n",
       "      <th>homeless</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.559150</td>\n",
       "      <td>0.802028</td>\n",
       "      <td>0.454467</td>\n",
       "      <td>0.467937</td>\n",
       "      <td>0.696474</td>\n",
       "      <td>0.428724</td>\n",
       "      <td>0.491324</td>\n",
       "      <td>0.567960</td>\n",
       "      <td>0.750028</td>\n",
       "      <td>0.189122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.642741</td>\n",
       "      <td>0.566048</td>\n",
       "      <td>0.533897</td>\n",
       "      <td>0.480772</td>\n",
       "      <td>0.556380</td>\n",
       "      <td>0.089049</td>\n",
       "      <td>0.424473</td>\n",
       "      <td>0.268013</td>\n",
       "      <td>0.658538</td>\n",
       "      <td>-0.015499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.262330</td>\n",
       "      <td>0.240296</td>\n",
       "      <td>0.758516</td>\n",
       "      <td>0.678734</td>\n",
       "      <td>0.310521</td>\n",
       "      <td>0.164318</td>\n",
       "      <td>0.286453</td>\n",
       "      <td>0.203065</td>\n",
       "      <td>0.441203</td>\n",
       "      <td>0.788052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262760</td>\n",
       "      <td>0.480219</td>\n",
       "      <td>0.319887</td>\n",
       "      <td>0.464563</td>\n",
       "      <td>0.261044</td>\n",
       "      <td>0.587798</td>\n",
       "      <td>0.128603</td>\n",
       "      <td>0.444031</td>\n",
       "      <td>0.349477</td>\n",
       "      <td>0.603952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.142139</td>\n",
       "      <td>0.422776</td>\n",
       "      <td>0.138751</td>\n",
       "      <td>0.087723</td>\n",
       "      <td>0.414351</td>\n",
       "      <td>0.225711</td>\n",
       "      <td>0.302220</td>\n",
       "      <td>0.172113</td>\n",
       "      <td>0.153584</td>\n",
       "      <td>0.274067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.525228</td>\n",
       "      <td>0.346378</td>\n",
       "      <td>0.236265</td>\n",
       "      <td>0.290491</td>\n",
       "      <td>0.242364</td>\n",
       "      <td>0.206138</td>\n",
       "      <td>0.764889</td>\n",
       "      <td>0.030127</td>\n",
       "      <td>0.235770</td>\n",
       "      <td>0.293672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.069198</td>\n",
       "      <td>-0.052656</td>\n",
       "      <td>0.168720</td>\n",
       "      <td>0.083585</td>\n",
       "      <td>0.260511</td>\n",
       "      <td>0.472473</td>\n",
       "      <td>0.369387</td>\n",
       "      <td>0.206922</td>\n",
       "      <td>0.133085</td>\n",
       "      <td>0.063767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172444</td>\n",
       "      <td>0.295814</td>\n",
       "      <td>0.491304</td>\n",
       "      <td>0.322113</td>\n",
       "      <td>0.078327</td>\n",
       "      <td>-0.024997</td>\n",
       "      <td>0.162073</td>\n",
       "      <td>0.170827</td>\n",
       "      <td>0.318039</td>\n",
       "      <td>0.304332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.095338</td>\n",
       "      <td>0.126932</td>\n",
       "      <td>0.067339</td>\n",
       "      <td>0.414472</td>\n",
       "      <td>0.019238</td>\n",
       "      <td>0.135389</td>\n",
       "      <td>0.062252</td>\n",
       "      <td>0.128646</td>\n",
       "      <td>0.203300</td>\n",
       "      <td>0.299587</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048517</td>\n",
       "      <td>-0.094704</td>\n",
       "      <td>0.089619</td>\n",
       "      <td>0.049355</td>\n",
       "      <td>0.266255</td>\n",
       "      <td>0.614700</td>\n",
       "      <td>0.171752</td>\n",
       "      <td>0.246698</td>\n",
       "      <td>0.080963</td>\n",
       "      <td>0.083757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.521357</td>\n",
       "      <td>0.108552</td>\n",
       "      <td>0.170841</td>\n",
       "      <td>0.084425</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.199444</td>\n",
       "      <td>0.027368</td>\n",
       "      <td>0.525760</td>\n",
       "      <td>0.230387</td>\n",
       "      <td>0.050137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227349</td>\n",
       "      <td>0.052107</td>\n",
       "      <td>0.029504</td>\n",
       "      <td>0.028232</td>\n",
       "      <td>0.367207</td>\n",
       "      <td>0.040128</td>\n",
       "      <td>0.020652</td>\n",
       "      <td>0.133911</td>\n",
       "      <td>0.090160</td>\n",
       "      <td>0.238523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.156429</td>\n",
       "      <td>0.149332</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>-0.013610</td>\n",
       "      <td>0.021649</td>\n",
       "      <td>-0.128033</td>\n",
       "      <td>0.090705</td>\n",
       "      <td>-0.035445</td>\n",
       "      <td>0.049393</td>\n",
       "      <td>-0.015276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070770</td>\n",
       "      <td>0.148605</td>\n",
       "      <td>0.219462</td>\n",
       "      <td>0.274342</td>\n",
       "      <td>0.112562</td>\n",
       "      <td>0.057057</td>\n",
       "      <td>0.180282</td>\n",
       "      <td>0.176836</td>\n",
       "      <td>0.051698</td>\n",
       "      <td>-0.166545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.085793</td>\n",
       "      <td>0.001485</td>\n",
       "      <td>0.172060</td>\n",
       "      <td>-0.127447</td>\n",
       "      <td>0.109134</td>\n",
       "      <td>-0.028697</td>\n",
       "      <td>0.183926</td>\n",
       "      <td>0.091577</td>\n",
       "      <td>0.016447</td>\n",
       "      <td>0.123880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010893</td>\n",
       "      <td>0.215381</td>\n",
       "      <td>0.072823</td>\n",
       "      <td>0.150118</td>\n",
       "      <td>0.047483</td>\n",
       "      <td>-0.140126</td>\n",
       "      <td>0.061309</td>\n",
       "      <td>-0.041219</td>\n",
       "      <td>-0.017611</td>\n",
       "      <td>0.036177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1077 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    million     right    crisis      stop      help      camp     child  \\\n",
       "0  0.559150  0.802028  0.454467  0.467937  0.696474  0.428724  0.491324   \n",
       "1  0.262330  0.240296  0.758516  0.678734  0.310521  0.164318  0.286453   \n",
       "2  0.142139  0.422776  0.138751  0.087723  0.414351  0.225711  0.302220   \n",
       "3  0.069198 -0.052656  0.168720  0.083585  0.260511  0.472473  0.369387   \n",
       "4  0.095338  0.126932  0.067339  0.414472  0.019238  0.135389  0.062252   \n",
       "5  0.521357  0.108552  0.170841  0.084425  0.001089  0.199444  0.027368   \n",
       "6  0.156429  0.149332  0.003215 -0.013610  0.021649 -0.128033  0.090705   \n",
       "7 -0.085793  0.001485  0.172060 -0.127447  0.109134 -0.028697  0.183926   \n",
       "\n",
       "       year      back   illegal  ...    funded  leverage   vehicle  \\\n",
       "0  0.567960  0.750028  0.189122  ...  0.642741  0.566048  0.533897   \n",
       "1  0.203065  0.441203  0.788052  ...  0.262760  0.480219  0.319887   \n",
       "2  0.172113  0.153584  0.274067  ...  0.525228  0.346378  0.236265   \n",
       "3  0.206922  0.133085  0.063767  ...  0.172444  0.295814  0.491304   \n",
       "4  0.128646  0.203300  0.299587  ... -0.048517 -0.094704  0.089619   \n",
       "5  0.525760  0.230387  0.050137  ...  0.227349  0.052107  0.029504   \n",
       "6 -0.035445  0.049393 -0.015276  ...  0.070770  0.148605  0.219462   \n",
       "7  0.091577  0.016447  0.123880  ...  0.010893  0.215381  0.072823   \n",
       "\n",
       "   weaponized      nine     naked    secure     alien    vessel  homeless  \n",
       "0    0.480772  0.556380  0.089049  0.424473  0.268013  0.658538 -0.015499  \n",
       "1    0.464563  0.261044  0.587798  0.128603  0.444031  0.349477  0.603952  \n",
       "2    0.290491  0.242364  0.206138  0.764889  0.030127  0.235770  0.293672  \n",
       "3    0.322113  0.078327 -0.024997  0.162073  0.170827  0.318039  0.304332  \n",
       "4    0.049355  0.266255  0.614700  0.171752  0.246698  0.080963  0.083757  \n",
       "5    0.028232  0.367207  0.040128  0.020652  0.133911  0.090160  0.238523  \n",
       "6    0.274342  0.112562  0.057057  0.180282  0.176836  0.051698 -0.166545  \n",
       "7    0.150118  0.047483 -0.140126  0.061309 -0.041219 -0.017611  0.036177  \n",
       "\n",
       "[8 rows x 1077 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor_dict =dict()\n",
    "for word,factor in zip(words_to_cluster,fa.loadings_):\n",
    "    factor_dict[word] = factor\n",
    "    \n",
    "factor_df = pd.DataFrame.from_dict(factor_dict)\n",
    "factor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>0.802028</td>\n",
       "      <td>0.240296</td>\n",
       "      <td>0.422776</td>\n",
       "      <td>-0.052656</td>\n",
       "      <td>0.126932</td>\n",
       "      <td>0.108552</td>\n",
       "      <td>0.149332</td>\n",
       "      <td>0.001485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>help</th>\n",
       "      <td>0.696474</td>\n",
       "      <td>0.310521</td>\n",
       "      <td>0.414351</td>\n",
       "      <td>0.260511</td>\n",
       "      <td>0.019238</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.021649</td>\n",
       "      <td>0.109134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>back</th>\n",
       "      <td>0.750028</td>\n",
       "      <td>0.441203</td>\n",
       "      <td>0.153584</td>\n",
       "      <td>0.133085</td>\n",
       "      <td>0.203300</td>\n",
       "      <td>0.230387</td>\n",
       "      <td>0.049393</td>\n",
       "      <td>0.016447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open</th>\n",
       "      <td>0.744733</td>\n",
       "      <td>0.195558</td>\n",
       "      <td>0.384544</td>\n",
       "      <td>0.104071</td>\n",
       "      <td>0.117539</td>\n",
       "      <td>0.029671</td>\n",
       "      <td>0.262515</td>\n",
       "      <td>-0.139846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>0.613226</td>\n",
       "      <td>0.363217</td>\n",
       "      <td>0.261500</td>\n",
       "      <td>0.173573</td>\n",
       "      <td>-0.027101</td>\n",
       "      <td>0.243353</td>\n",
       "      <td>0.040545</td>\n",
       "      <td>-0.013139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>couple</th>\n",
       "      <td>0.611650</td>\n",
       "      <td>0.216561</td>\n",
       "      <td>0.399804</td>\n",
       "      <td>0.270981</td>\n",
       "      <td>0.043119</td>\n",
       "      <td>0.145314</td>\n",
       "      <td>-0.047949</td>\n",
       "      <td>0.045120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gather</th>\n",
       "      <td>0.787129</td>\n",
       "      <td>0.264692</td>\n",
       "      <td>0.233996</td>\n",
       "      <td>0.273640</td>\n",
       "      <td>0.108069</td>\n",
       "      <td>0.098242</td>\n",
       "      <td>0.100004</td>\n",
       "      <td>-0.055289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grow</th>\n",
       "      <td>0.684127</td>\n",
       "      <td>0.225808</td>\n",
       "      <td>0.238009</td>\n",
       "      <td>0.271731</td>\n",
       "      <td>0.086286</td>\n",
       "      <td>0.230837</td>\n",
       "      <td>0.218085</td>\n",
       "      <td>-0.006097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funded</th>\n",
       "      <td>0.642741</td>\n",
       "      <td>0.262760</td>\n",
       "      <td>0.525228</td>\n",
       "      <td>0.172444</td>\n",
       "      <td>-0.048517</td>\n",
       "      <td>0.227349</td>\n",
       "      <td>0.070770</td>\n",
       "      <td>0.010893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vessel</th>\n",
       "      <td>0.658538</td>\n",
       "      <td>0.349477</td>\n",
       "      <td>0.235770</td>\n",
       "      <td>0.318039</td>\n",
       "      <td>0.080963</td>\n",
       "      <td>0.090160</td>\n",
       "      <td>0.051698</td>\n",
       "      <td>-0.017611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>588 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "right   0.802028  0.240296  0.422776 -0.052656  0.126932  0.108552  0.149332   \n",
       "help    0.696474  0.310521  0.414351  0.260511  0.019238  0.001089  0.021649   \n",
       "back    0.750028  0.441203  0.153584  0.133085  0.203300  0.230387  0.049393   \n",
       "open    0.744733  0.195558  0.384544  0.104071  0.117539  0.029671  0.262515   \n",
       "news    0.613226  0.363217  0.261500  0.173573 -0.027101  0.243353  0.040545   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "couple  0.611650  0.216561  0.399804  0.270981  0.043119  0.145314 -0.047949   \n",
       "gather  0.787129  0.264692  0.233996  0.273640  0.108069  0.098242  0.100004   \n",
       "grow    0.684127  0.225808  0.238009  0.271731  0.086286  0.230837  0.218085   \n",
       "funded  0.642741  0.262760  0.525228  0.172444 -0.048517  0.227349  0.070770   \n",
       "vessel  0.658538  0.349477  0.235770  0.318039  0.080963  0.090160  0.051698   \n",
       "\n",
       "               7  \n",
       "right   0.001485  \n",
       "help    0.109134  \n",
       "back    0.016447  \n",
       "open   -0.139846  \n",
       "news   -0.013139  \n",
       "...          ...  \n",
       "couple  0.045120  \n",
       "gather -0.055289  \n",
       "grow   -0.006097  \n",
       "funded  0.010893  \n",
       "vessel -0.017611  \n",
       "\n",
       "[588 rows x 8 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor_df_transposed = factor_df.T \n",
    "factor_df_transposed[factor_df_transposed[0]>0.6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering frame modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import umap.umap_ as umap\n",
    "start = time()\n",
    "reducer = umap.UMAP(random_state=42,n_components=3)\n",
    "reduced_embedding = reducer.fit_transform(words_embeddings)\n",
    "print(f'Duration: {time() - start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "start = time()\n",
    "cluster_labels = DBSCAN(min_samples=6).fit_predict(reduced_embedding)\n",
    "print(f'Duration: {time() - start} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AffinityPropagation\n",
    "\n",
    "start = time()\n",
    "cluster_labels = AffinityPropagation().fit_predict(reduced_embedding)\n",
    "print(f'Duration: {time() - start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "k_clusters = KMeans(n_clusters=8, random_state=42).fit_predict(reduced_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn\n",
    "\n",
    "seaborn.scatterplot(x = reducer.embedding_[:, 0],\n",
    "                y = reducer.embedding_[:, 1],\n",
    "                hue = cluster_labels, palette =\"Paired\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection = '3d')\n",
    "\n",
    "x = reducer.embedding_[:, 0]\n",
    "y = reducer.embedding_[:, 1]\n",
    "z = reducer.embedding_[:, 2]\n",
    "\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_zlabel(\"z\")\n",
    "\n",
    "ax.scatter(x, y, z, c = cluster_labels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labeled_tweets = pd.DataFrame({'word': words_to_cluster,'label':cluster_labels})\n",
    "\n",
    "# Create documents per label\n",
    "docs_per_class = labeled_tweets.groupby(['label'], as_index=False).agg({'word': ' '.join})\n",
    "\n",
    "words_per_class = dict()\n",
    "for label,word in zip(docs_per_class['label'],docs_per_class['word']):\n",
    "    words_per_class[label] = word.split(' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in words_per_class.items() ])).fillna('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "def kmean_test_n_clusters(data, n_clusters):\n",
    "    \"\"\"\n",
    "    Takes the document vectors and the maximum amount of clusters to look for. \n",
    "    Performs KMeans algorithm on the dataset for each amount of clusters. \n",
    "    Calculates silhouette score and interias for each amount of clusters. \n",
    "    Plots the scores as a function of the amount of clusters.\n",
    "    \n",
    "    Arguments: \n",
    "    data -- document vectors as numpy matrices\n",
    "    n_clusters -- integer that determines the maximum amount of clusters to test\n",
    "    \n",
    "    Returns: \n",
    "    Prints the scores as functions of the clusters in range 1, n_clusters\n",
    "    \"\"\"\n",
    "    n_clusters += 1\n",
    "    kmeans_per_k = [KMeans(n_clusters=k, random_state=42).fit(data) for k in tqdm(range(1, n_clusters))]\n",
    "    print(\"clusters done\")\n",
    "    inertias = [model.inertia_ for model in kmeans_per_k]\n",
    "    print(\"inertias done\")\n",
    "    silhouette_scores = [silhouette_score(data, model.labels_)\n",
    "                         for model in tqdm(kmeans_per_k[1:])]\n",
    "    print(\"silhouettes done\")\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2,1, figsize=(8, 3.5))\n",
    "\n",
    "    ax1.plot(range(1, n_clusters), inertias, \"bo-\")\n",
    "    ax1.set_xlabel(\"$k$\", fontsize=14)\n",
    "    ax1.set_ylabel(\"Inertia\", fontsize=14)\n",
    "    #ax1.annotate('Elbow',\n",
    "    #             xy=(4, inertias[3]),\n",
    "    #             xytext=(0.55, 0.55),\n",
    "    #             textcoords='figure fraction',\n",
    "    #             fontsize=16,\n",
    "    #             arrowprops=dict(facecolor='black', shrink=0.1)\n",
    "    #            )\n",
    "    ax2.plot(range(2, n_clusters), silhouette_scores, \"bo-\")\n",
    "    ax2.set_xlabel(\"$k$\", fontsize=14)\n",
    "    ax2.set_ylabel(\"Silhouette score\", fontsize=14)\n",
    "    #plt.axis([2, 8, 0.3, 0.475])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmean_test_n_clusters(reduced_embedding, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train this model only after the first merging step to save both memory and time\n",
    "words_to_cluster =  [\"accept\" ,        \"ally\"     ,      \"army\"     ,      \"attack\"     ,    \"attacking\"  ,    \"authority\"   ,   \"benefit\"       \n",
    ",\"billion\"    ,    \"blackmail\"    ,  \"block\"   ,       \"boat\"    ,       \"bomb\"     ,      \"bombing\"  ,      \"border\"        \n",
    ",\"break\"       ,   \"build\"   ,       \"burden\"    ,     \"camp\" ,          \"care\"      ,     \"child\",          \"citizen\"       \n",
    ",\"city\"       ,    \"civil\"    ,      \"civilian\" ,      \"clash\" ,         \"closed\"         ,\"coast\" ,         \"community\"     \n",
    ",\"conflict\"  ,     \"control\"   ,     \"creating\",       \"crime\"  ,        \"criminal\"      , \"cross\"  ,        \"crossing\"      \n",
    ",\"dead\"     ,      \"death\"      ,    \"defend\" ,        \"desperate\",      \"dictator\"     ,  \"displaced\",      \"door\"          \n",
    ",\"economic\",       \"economy\"     ,   \"entering\"       ,\"entry\"     ,     \"family\"      ,   \"fear\"      ,     \"fence\"         \n",
    ",\"fight\"          ,\"fighting\"     ,  \"fire\"          , \"fled\"       ,    \"flee\"       ,    \"fleeing\"    ,    \"flood\"         \n",
    ", \"flow\"         ,  \"food\"         ,  \"force\"       ,   \"forced\"     ,    \"foreign\"  ,      \"friend\"     ,    \"game\"          \n",
    " ,\"gate\"        ,   \"government\"    , \"guard\"      ,    \"health\"      ,   \"help\"    ,       \"helping\"     ,   \"history\"       \n",
    ", \"hold\"       ,    \"hope\"           ,\"host\"      ,     \"hosting\"      ,  \"house\"  ,        \"human\"        ,  \"humanitarian\"  \n",
    ",\"humanity\"   ,    \"hundred\"  ,      \"illegal\"   ,     \"illegally\"      ,\"influx\" ,        \"innocent\"       ,\"invade\"        \n",
    ", \"invader\"  ,      \"invading\" ,      \"invasion\",       \"islamic\"        ,\"jihadist\"      , \"kid\" ,           \"kill\"          \n",
    ",\"killed\"   ,      \"killing\"    ,    \"leaving\" ,       \"legal\"   ,       \"march\"         , \"mass\"  ,         \"military\"      \n",
    ", \"million\"       , \"minister\"   ,    \"money\"         , \"movement\",       \"national\"    ,   \"number\",         \"official\"      \n",
    ", \"opening\"      ,  \"order\"       ,   \"peace\"        ,  \"picture\"  ,      \"police\"     ,    \"policy\" ,        \"population\"    \n",
    ", \"power\"       ,   \"pressure\"     ,  \"prevent\"     ,   \"protect\"   ,     \"protection\",     \"pushing\" ,       \"refuge\"        \n",
    ",\"regime\"      ,   \"region\"         ,\"respect\"     ,   \"responsibility\", \"return\"    ,     \"risk\"      ,     \"rule\"          \n",
    ",\"safety\"     ,    \"school\"    ,     \"security\"   ,    \"shelter\" ,       \"shooting\" ,      \"shot\"       ,    \"social\"        \n",
    ",\"soldier\"      ,  \"solidarity\" ,    \"solution\"  ,     \"suffering\",      \"support\" ,       \"supporting\"  ,   \"tension\"       \n",
    ", \"territory\"  ,    \"terrorist\"  ,    \"thousand\",       \"threat\"   ,      \"travel\",         \"troop\"       ,   \"violence\"      \n",
    ", \"war\"       ,     \"wave\"        ,   \"weapon\" ,        \"woman\"     ,     \"work\" ,          \"worker\"       ,  \"working\"       \n",
    ", \"zone\"]\n",
    "\n",
    "print(unique_tweets_df['text_alphanum'].shape)\n",
    "len(words_to_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
